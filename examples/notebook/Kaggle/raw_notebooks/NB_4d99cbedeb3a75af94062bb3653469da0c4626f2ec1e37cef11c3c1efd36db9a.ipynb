{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Online Learning Perceptro in Python\n파이썬으로 표준 라이브러리를 사용해서 위의 퍼셉트론 알고리즘을 구현했기 때문에 스크립트가 PyPy에서 실행되고 3-4배의 속도향상이 있다. 여기에 사용된 알고리즘은 Kaggle 포럼에서 처음 발견 된 tinrtgu의 온라인 로지스틱 회귀 스크립트에서 큰 영감을 얻었다고 한다.\n\n다음 경진대회에서 Vowpal Wabbit을 통한 해시트릭을 사용하였고 코드가 공개되어 있다.\n\nDisplay Advertising Challenge - Kaggle, Beat the benchmark with less then 200MB of memory.\n코드 : https://kaggle2.blob.core.windows.net/forum-message-attachments/53646/1539/fast_solution.py"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## 해싱 트릭\n벡터화 해싱트릭은 Vowpal Wabbit(John Langford)에서 시작되었다. 이 트릭은 퍼셉트론으로 들어오는 연결 수를 고정 된 크기로 설정한다. 고정 된 크기보다 낮은 숫자로 모든 원시 피처를 해싱한다. Vowpal Wabbit은 모든 데이터를 메모리로 읽어들이지 않고 모델을 훈련시킬 수 있는 빠른 머신러닝 라이브러리다."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sample = 'This movie sucks'\nfixed_size = 1024\n\nprint(sample.split())\n\nfeatures = [(hash(f)%fixed_size, 1) for f in sample.split()]\n\n# list of tuples in form (feature_index, feature_value)\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data extract"},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv.zip\n!unzip /kaggle/input/word2vec-nlp-tutorial/testData.tsv.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 프로그레시브 검증 손실\n한 번에 하나씩 표본을 학습하면 점신적으로 train loss가 된다. 모델이 타겟을 보지않고 첫 샘플을 보고 예측을 한다. 그런 다음 예측을 대상 레이블과 비교하여 오류율을 계산한다. 오류율이 낮으면 좋은 모델에 가깝다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport random\nfrom math import exp, log\nfrom datetime import datetime\nfrom operator import itemgetter # 키가 아닌 값으로 max, min 값을 구할 때 사용","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(s):\n    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_tsv(loc_dataset, opts):\n    for e, line in enumerate(open(loc_dataset, 'rb')):\n        if e > 0:\n            r = line.decode('utf-8').strip().split('\\t')\n            id = r[0]\n            \n            if opts['clean']:\n                try:\n                    r[2] = clean(r[2])\n                except:\n                    r[1] = clean(r[1])\n            \n            if len(r) == 3:\n                features = [(hash(f)%opts['D'], 1) for f in r[2].split()]\n                label = int(r[1])\n            else:\n                features = [(hash(f)%opts['D'], 1) for f in r[1].split()]\n                label = 1\n            \n            if opts['2grams']:\n                for i in range(len(features)-1):\n                    features.append(\n                        (hash(str(features[i][0])+str(features[i+1][0]))%opts['D'], 1))\n            yield label, id, features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dot_product(features, weights):\n    dotp = 0\n    for f in features:\n        dotp += weights[f[0]]*f[1]\n    return dotp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_tron(loc_dataset, opts):\n    start = datetime.now()\n    print('\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start')\n    \n    # 가중치 초기화\n    if opts['random_init']:\n        random.seed(3003)\n        weight = [random.random()] * opts['D']\n    else:\n        weights = [0.] * opts['D']\n    \n    # Running training passes\n    # 학습 실행\n    for pass_nr in range(opts['n_passes']):\n        error_counter = 0\n        for e, (label, id, features) in enumerate( \\\n            get_data_tsv(loc_dataset, opts)):\n            \n            # 퍼셉트론은 지도학습 분류기의 일종\n            # 이전 값에 대한 학습으로 예측\n            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라\n            # 초과하면 1을 예측하고 미만이면 0을 예측한다.\n            dp = dot_product(features, weights) > 0.5\n            \n            # 다음 perceptron은 샘플의 레이블을 본다.\n            # 실제 레이블 데이터에서 위 퍼셉트론으로 구한 dp 값을 빼준다.\n            # 예측이 정확하다면 error 값은 0이며, 가중치만 남겨둔다.\n            # 예측이 틀린 경우 error값은 1 또는 -1이고 다음과 같이 가중치를 업데이트 한다.\n            # weights[feature_index] += learning_rate * error * feature_value\n            \n            error = label - dp\n            \n            # 예측이 틀린 경우 퍼셉트론은 다음과 같이 가중치를 업데이트 한다.\n            if error != 0:\n                error_counter += 1\n                # updating the weights\n                for index, value in features:\n                    weights[index] += opts['learning_rate'] * error * log(1.+value)\n        \n        # Reporting stuff\n        print('%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s' % (\\\n                pass_nr+1,\n                error_counter,\n                round(1 - error_counter / float(e+1), 5),\n                e+1, datetime.now()-start))\n        \n        # Oh heh, we have overfit :)\n        if error_counter == 0 or error_counter < opts['errors_satisfied']:\n            print('%s erros found during training, halting' % error_counter)\n            break\n    return weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_tron(loc_dataset,weights,opts):\n    \"\"\"\n        output:\n                preds: list, a list with\n                [id,prediction,dotproduct,0-1normalized dotproduct]\n    \"\"\"\n    start = datetime.now()\n    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n    preds = []\n    error_counter = 0\n    for e, (label, id, features) in enumerate( \\\n        get_data_tsv(loc_dataset,opts) ):\n\n        dotp = dot_product(features, weights)\n        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n        dp = dotp > 0.5\n        if dp > 0.5: # we predict positive class\n            preds.append( [id, 1, dotp ] )\n        else:\n            preds.append( [id, 0, dotp ] )\n        \n        # get_data_tsv에서 테스트 데이터의 레이블을 1로 초기화 해주었음\n        if label - dp != 0:\n            error_counter += 1\n\n    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n        error_counter,\n        round(1 - error_counter /float(e+1),5),\n        e+1,\n        datetime.now()-start))\n\n    # normalizing dotproducts between 0 and 1 \n    # 내적을 구해 0과 1로 일반화 한다.\n    # TODO: proper probability (bounded sigmoid?), \n    # online normalization\n    max_dotp = max(preds,key=itemgetter(2))[2]\n    min_dotp = min(preds,key=itemgetter(2))[2]\n    for p in preds:\n        # appending normalized to predictions\n        # 정규화 된 값을 마지막에 추가해 준다.\n        # (피처와 가중치에 대한 내적값 - 최소 내적값) / 최대 내적값 - 최소 내적값\n        # 이 값이 캐글에서 0.95의 AUC를 얻을 수 있는 값이다.\n        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) \n        \n    #Reporting stuff\n    print(\"Done testing in %s\"%str(datetime.now()-start))\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting options\nopts = {}\nopts[\"D\"] = 2 ** 25\nopts[\"learning_rate\"] = 0.1\nopts[\"n_passes\"] = 80 # Maximum number of passes to run before halting\nopts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\nopts[\"random_init\"] = False # set random weights, else set all 0\nopts[\"clean\"] = True # clean the text a little\nopts[\"2grams\"] = True # add 2grams\n\n#training and saving model into weights\n%time \nweights = train_tron(PATH+\"labeledTrainData.tsv\",opts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing and saving predictions into preds\n%time \npreds = test_tron(PATH+\"testData.tsv\",weights,opts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 캐글 점수 제출을 위한 서브미션 파일을 작성한다.\nwith open(\"submit_perceptron.csv\",\"wb\") as outfile:\n    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n    for p in sorted(preds):\n        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}