{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393d4db4-6a03-4975-bdcf-3c22ae8964ea",
   "metadata": {},
   "source": [
    "## Download notebooks from Github\n",
    "Given a Github repo link, we download the Jupyter notebooks from the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed47815-9753-476b-8a96-99749fd95de1",
   "metadata": {},
   "source": [
    "## Use PyGithub\n",
    "+ We use PyGithub API to traverse a repository and download .ipynb files from the repo. \n",
    "+ `id = hashlib.sha256(html_url)` is used to generate ID for notebook\n",
    "+ We use a `notebook_metadata` to record the id and some other metadata for the notebooks\n",
    "+ We use `repo_download_log` to keep reack of the repos being downloaded, making it possible to consume downloading and skip the notebook already exists. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb63eac-bee8-4464-ad17-54d1f115ae9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from github import Github\n",
    "from github.GithubException import RateLimitExceededException\n",
    "import hashlib\n",
    "import csv\n",
    "import datetime\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b64740f-88e6-484a-a970-28ea1da9aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL_FILE_JUPYTER_WIKI = 'repo_links/jupyter_wiki/github_links.txt'\n",
    "REPO_URL_FILE_COLLECTED_QUERIES = 'repo_links/collected_queries_repo_urls.txt'\n",
    "# METADATA_LOG_JUPYTER_WIKI = 'download_logs/notebook_metadata_jupyter_wiki.csv'\n",
    "# METADATA_LOG_COLLECTED_QUERIES = 'download_logs/notebook_metadata_collected_queries.csv'\n",
    "REPO_DOWNLOAD_LOG = 'download_logs/repo_download_log.csv'\n",
    "NOTEBOOK_CONTENT_PATH = 'notebook_contents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07bb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_csv(file_path, row):\n",
    "    with open(file_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187f1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_record_in_csv(file_path, search_dict, search_field):\n",
    "    ''' Check the record in csv file'''\n",
    "    # open the CSV file and read it into a list of dictionaries\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "\n",
    "    # search for a record with a specific value in a field\n",
    "    found = False\n",
    "    for record in data:\n",
    "        if record[search_field] == search_dict[search_field]:\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if found:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127f460f-bec1-4cc8-a4f9-075a8c7de490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Traverse the Github repo and download notebooks\n",
    "def traverse_contents(contents, dst_dir):\n",
    "    for content_file in contents:\n",
    "        if content_file.type == 'dir':\n",
    "            traverse_contents(repo.get_contents(content_file.path), dst_dir)\n",
    "        elif content_file.name.endswith('.ipynb'):\n",
    "            # Compute the SHA-256 hash of the html_url as the ID for the notebook\n",
    "            notebook_id = 'NB_'+hashlib.sha256(content_file.html_url.encode('utf-8')).hexdigest()\n",
    "            # print(notebook_id)\n",
    "            notebook_path = os.path.join(dst_dir, notebook_id+'.ipynb')\n",
    "            metadata_path = os.path.join(dst_dir, notebook_id+'.json')\n",
    "            # print(path)\n",
    "            \n",
    "            if not os.path.exists(metadata_path):\n",
    "                # Store metadata\n",
    "                ipynb_info = get_ipynb_info(content_file, notebook_id)\n",
    "                with open(metadata_path, 'w') as f:\n",
    "                    json.dump(ipynb_info, f)\n",
    "                    print(f\"Metadata: {ipynb_info['docid']}\")\n",
    "            \n",
    "            # Download notebook file only if there is no record in the metadata log\n",
    "            if not os.path.exists(notebook_path): \n",
    "                download_file(content_file, notebook_path)\n",
    "                print(f\"Notebook: {notebook_path}\")\n",
    "\n",
    "\n",
    "def download_file(content_file, path):\n",
    "    response = requests.get(content_file.download_url)\n",
    "    if response.status_code == 200:\n",
    "        # dirname = os.path.dirname(path)\n",
    "        # if dirname != '':\n",
    "        #     os.makedirs(dirname, exist_ok=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    elif response.status_code == 429:\n",
    "            # If we get a 429 error, wait for the recommended number of seconds and retry the request\n",
    "            retry_after = response.headers.get('Retry-After')\n",
    "            if retry_after:\n",
    "                retry_after_secs = int(retry_after)\n",
    "                print(f'Rate limit exceeded. Waiting for {retry_after_secs} seconds before retrying...')\n",
    "                time.sleep(retry_after_secs)\n",
    "                return download_file(content_file, path)\n",
    "    else: \n",
    "        return -1\n",
    "            \n",
    "def get_ipynb_info(content_file, notebook_id):  \n",
    "    # Extract the relevant metadata from the ContentFile object\n",
    "    ipynb_info = {\n",
    "        'docid': notebook_id,\n",
    "        'path': content_file.path,\n",
    "        'name': os.path.basename(content_file.path),\n",
    "        'html_url': content_file.html_url,\n",
    "        'url': content_file.url,\n",
    "        'size': content_file.size,\n",
    "        'sha': content_file.sha,\n",
    "        'git_url': content_file.git_url,\n",
    "        'download_url': content_file.download_url,\n",
    "        'type': content_file.type,\n",
    "        'encoding': content_file.encoding,\n",
    "        'last_modified': content_file.last_modified\n",
    "    }\n",
    "    return ipynb_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591f587d-e2ed-4633-87ff-a80fb583fd75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rate_limit_info(g): \n",
    "    # Get the rate limit information from the last response\n",
    "    rate_limit = g.get_rate_limit()\n",
    "    rate_remaining = rate_limit.core.remaining\n",
    "    rate_reset_utc = rate_limit.core.reset\n",
    "\n",
    "    # Convert UTC time to local time zone\n",
    "    local_tz = pytz.timezone('Europe/Amsterdam')  # Replace with your local time zone\n",
    "    rate_reset = rate_reset_utc.replace(tzinfo=pytz.utc).astimezone(local_tz)\n",
    "\n",
    "    # Print the rate limit information\n",
    "    print(f\"Rate limit: {rate_limit}\")\n",
    "    print(f\"Rate remaining: {rate_remaining}\")\n",
    "    print(f\"Rate reset time: {rate_reset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3169a1ab-94fe-44f4-945e-a2b93d00ca71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get github access token\n",
    "with open('github_token.json', 'r') as f:\n",
    "    # Load the JSON data into a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "# Access the values of the 'user' and 'token' keys\n",
    "user = data['user']\n",
    "token = data['token']\n",
    "\n",
    "# Provide your access token or username and password\n",
    "g = Github(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05221f71-dd26-410a-a857-222dd2b7e01e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/ericnjogu/secure-ai-deep-learning-v2-pytorch', 'https://github.com/eastmountyxz/ImageProcessing-Python', 'https://github.com/y-richie-y/badgraphs', 'https://github.com/stes/saliency', 'https://github.com/brechtvandervliet/ResistancePoisoningFederatedMalwareClassifier']\n",
      "915\n"
     ]
    }
   ],
   "source": [
    "# Get repo URLs\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "\n",
    "with open(REPO_URL_FILE_COLLECTED_QUERIES, 'r') as f:\n",
    "    urls = f.readlines()\n",
    "    repo_urls = [url.strip() for url in urls]\n",
    "print(repo_urls[:5])\n",
    "print(len(repo_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d0b2af5-483f-42af-b450-72259618b468",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ericnjogu/secure-ai-deep-learning-v2-pytorch\n",
      "[1] eastmountyxz/ImageProcessing-Python\n",
      "[2] y-richie-y/badgraphs\n",
      "[3] stes/saliency\n",
      "[4] brechtvandervliet/ResistancePoisoningFederatedMalwareClassifier\n",
      "[5] ZoyaGul/Histogram-Equalization-with-RGB\n",
      "[6] cansuyalcinn/lung-ct-registration-challenge\n",
      "[7] adi112100/-Understanding-and-Predicting-Property-Maintenance-Fines\n",
      "[8] Western-OC2-Lab/SB-PdM-a-tool-for-predictive-maintenance-of-rolling-bearings-based-on-limited-labeled-data\n",
      "[9] ElsaScola/DeepNeuralNetworks-BrainComputerInterfaces-analysis\n",
      "[10] WeeYL/capstone\n",
      "[11] fherreralab/organic-microcavity-spectra\n",
      "[12] ybliu9/Cancer_object_detection_dnn\n",
      "[13] jasonhernacki/poincare-embeddings\n",
      "[14] GrindSC/C-code-generation-rnn\n",
      "[15] AmeenAshad19/Saliency-Detection-Using-DMD-and-its-Variants\n",
      "[16] natandrade/Tutorial-Medical-Image-Registration\n",
      "[17] simonegiancola09/university_test_rankings\n",
      "[18] leighirving/sales-conversion-optimization\n",
      "[19] jugal-krishna/Debiasing\n",
      "[20] Mithrillion/EarthEngineDataProcessing\n",
      "[21] AzeemWaqarRao/cifar10-image-recognition\n",
      "[22] naruya/aruco\n",
      "[23] jejrhom/Super_Bowl_analysis\n",
      "[24] darylchang123/camelyon\n",
      "[25] corawent/tmd-model\n",
      "[26] Saster-He/Bio-Algorithm\n",
      "[27] varyshare/newbie_neural_network_practice\n",
      "[28] cassiescyphers/facebook_ad_analysis\n",
      "[29] Osama-Sayed/Automated-Intelligent-Model-for-Students-Concentration-Measurement.pd\n",
      "[30] tobias-fritz/Spectral-vis\n",
      "[31] ASethi04/Generation-of-Novel-Drug-Molecules-with-Specific-Protein-Targets-Through-a-Graph-Network-and-Custom-\n",
      "[32] yasserhessein/deep-learning-classification-mammographic-mass\n",
      "[33] ooovector/qsweepy-notebooks\n",
      "[34] VellummyilumVinoth/CPU_Memory_Usage\n",
      "Add NB_7b737f07692d8cc0955450ee42fc07dba466cc980c5186bc37ea8da4604f04fe\n",
      "Write to notebook_contents/NB_7b737f07692d8cc0955450ee42fc07dba466cc980c5186bc37ea8da4604f04fe.ipynb\n",
      "[35] hashk1/japanese-wordnet-poincare\n",
      "[36] Lavode/41109-privacy-and-data-security\n",
      "[37] dietahanson/breast_cancer_classification\n",
      "[38] seema25-more/Food-Vision-Mini\n",
      "[39] allen-chiang/Time-Series-Transformer\n",
      "[40] abdullah1107/Movie_Recommendation_System\n",
      "[41] kmmrao/read_hdf4_file\n",
      "[42] sofiavera/medical_image_analysis_20_21\n",
      "[43] zhpinkman/tcp-congestion-control\n",
      "[44] rishabhathiya/Stock-prediction\n",
      "[45] brugalada/Jacobian\n",
      "[46] yanruc123/Cancer-Metastasis-Detection-on-Gigapixel-Pathology-Images\n",
      "[47] wuxxx949/stock_embedding\n",
      "[48] tinagoetschi/myTestRepo2\n",
      "[49] cwfparsonson/ddls\n",
      "[50] gregnordin/3dprinter_resin_spectra\n",
      "[51] ClimateTools/field_correlation\n",
      "[52] rashmi315/Finding_donors_ML\n",
      "[53] nishantk2106/GoogleSvrLog_dataset_python\n",
      "[54] zahta/graph_ml\n",
      "Add NB_41357f5f3dce29faaf99beefc343c3fa97fe1573b1878303000ab36c23ab8d01\n",
      "Write to notebook_contents/NB_41357f5f3dce29faaf99beefc343c3fa97fe1573b1878303000ab36c23ab8d01.ipynb\n",
      "[55] nafisa-samia/Weather-Prediction-using-Linear-Regression\n",
      "[56] millingab/multiview-stereo\n",
      "[57] brfi3983/Manifold-Optimization\n",
      "[58] bideeen/Building-A-Trading-Strategy-With-Python\n",
      "[59] mi-erasmusmc/omop-poincare\n",
      "[60] Mingxue-Li/Fraud-Detection\n",
      "[61] DeyPoulomi/Uk-Ad-spent-Analysis\n",
      "[62] yw3xs/PPDL\n",
      "[63] PV-Lab/BayesProcess\n",
      "[64] Hyradus/HyperspectralData-Notebook\n",
      "[65] meettyj/Recipe2Vec\n",
      "[66] MRYingLEE/Time-series-Preprocessing-Studio-in-Jupyter\n",
      "[67] Mansi-khemka/Cancer-Metastases-Segmentation-in-Gigapixel-Pathology-Images\n",
      "[68] wesley-kayanan/gene-smd-plants-som\n",
      "[69] sci-bots/inferado\n",
      "[70] imatge-upc/saliency-2016-lsun\n",
      "[71] BenetManzanaresSalor/TextRe-Identification\n",
      "[72] ziofil/live_plot\n",
      "[73] flekschas/higlass-scalable-insets\n",
      "[74] srin20/Simple-Linear-Regression-model-on-Salary-data-to-predict-Test-sets-of-Salary-Vs.-Experience\n",
      "[75] meganzoe/ipmi-registration\n",
      "[76] NNSatyaKarthik/DeBruijnGraph\n",
      "[77] yuhaozhang94/changi-airport-taxiway-planning\n",
      "[78] gjunqueira-sys/ResourceManagement.jl\n",
      "[79] neeta18/Statistical-Analysis\n",
      "[80] BiCroLab/nucleAI\n",
      "[81] Deena-Gergis/pandas_timeseries_tutorial\n",
      "[82] john-breton/WATER\n",
      "[83] Ali5hadman/Time-series-Classification-using-recurrent-neural-networks-\n",
      "[84] kalyanainala/Finding-Donors-for-CharityML\n",
      "[85] Parker730/Resteraunt-Rating-Predication-application\n",
      "[86] senyosimpson/DIR\n",
      "[87] anushabharati/DataAnalysisusingPython\n",
      "[88] Ajitesh27/New-York-Airbnb-Data-Analytics-and-Price-Prediction\n",
      "[89] iAbhyuday/Facial-Keypoints-Detection\n",
      "[90] jcchan23/CoMPT\n",
      "[91] imsaksham-c/FacialLandmarks\n",
      "[92] klimanyusuf/Twitter-Hate\n",
      "[93] HuanranLi/GrassCare-Plot\n",
      "[94] FATHIMA-SHEMEEMA/REAL-TIME-GENDER-DETECTION\n",
      "[95] razzant/VLSaliency\n",
      "[96] Sma6500/Last_year_project\n",
      "[97] PantelisElinas/Graph-Representation-Learning-Tutorial\n",
      "[98] kcisowska/PerformanceTest-bubble_and_quick_sort\n",
      "[99] VishaniRaveendran/Text-to-code-Generation\n",
      "[100] dhwani77/Web-Scrapping-Ebay-search-results-for-iPhones\n",
      "[101] JINODK/AR-ArUco-video-embed\n",
      "[102] JesseBausell/Hydrolight53_Bootstrap\n",
      "[103] ccasis/SIT719\n",
      "[104] sabrinali18/Detecting-Cancer-Metastases\n",
      "[105] jing-xue/PredictCancer\n",
      "[106] arjun06patil/Automatic_Text_Generation-\n",
      "[107] akumar1903/S3-Redshift-Integration\n",
      "[108] pikkaay/Restore-tensorflow-model\n",
      "[109] theBlackCub/Plotly-Cufflinks\n",
      "[110] BALaka-18/EDA-on-the-IPL-Dataset\n",
      "[111] carlotta-marchis/breast-cancer-detection\n",
      "[112] ellolo/visual-keras\n",
      "[113] rahulshenoy77/Medical-Image-Registration\n",
      "[114] ounadi/Medical-image-registration\n",
      "[115] NamanBiyani06/HandPoseDetection\n",
      "[116] klimanyusuf/Combating-Twitter-Hate-Speech-Using-ML-and-NLP\n",
      "[117] alitk/DeepRL-RRM\n",
      "[118] SeanOhAileasa/syp-risk-management-privacy-and-sensitive-data-security\n",
      "[119] lantzo/effective-rank\n",
      "[120] sumanyurosha/udacity-secure-and-private-ai\n",
      "[121] Lorsmo/Repo-ETL-Project-\n",
      "[122] ashna111/multimodal-image-fusion-to-detect-brain-tumors\n",
      "[123] MbProg/Anomaly-detection-of-timeseries\n",
      "[124] eahussein/bladder_cancer\n",
      "[125] MuhammadAli2902/Airflight-Delay-Classifier\n",
      "[126] rastadayon/TCP-Congestion-Control-Analysis\n",
      "[127] alakamale/VisualizingGit\n",
      "[128] rsriram315/eds_covid-19\n",
      "[129] jasjahan/CSC852-Security_and_Data_Privacy_Assignments\n",
      "[130] 3sarojbhattarai/Deep-Learning-Nanodegree-Udacity\n",
      "[131] mhamilton723/STEGO\n",
      "[132] AlessandraSozzi/Lucene-python\n",
      "[133] cloud-np/Task-Scheduling-Grid\n",
      "[134] RuoyuGuo/Visualising-Image-Classification-Models-and-Saliency-Maps\n",
      "[135] piyush2896/Facial-Expression-Recognition-Challenge\n",
      "[136] RisticDjordje/daily-task-scheduler\n",
      "[137] modidhaval112/SOEN_6611_Software_Measurement\n",
      "[138] sgaseretto/nopeeknn\n",
      "[139] Egorokm19/Adaptive-TCP-algorithm-based-on-machine-learning-in-telecommunication-networks\n",
      "[140] grohit868/LSTM-Model-to-predict-Future-stock-price-of-Infosys-Shares.\n",
      "[141] FLGraduationProject/FLwithPS\n",
      "[142] SR42-dev/olympic-athlete-dataset-analysis\n",
      "[143] baller609/Directed-Acyclic-Graph\n",
      "[144] waweru-wanjiru/Sendy-Logistic-Challenge\n",
      "[145] 96harsh52/-Side-Face-to-Front-Face-Conversion-using-Pix2Pix-Gan\n",
      "[146] abdullah2297/Finding_donors\n",
      "[147] think-high/Text_to_Knowledge_Graph\n",
      "[148] akshay1621997/Vision-based-Congestion-Controlled-System-using-Opencv\n",
      "[149] johanDDC/RiemannianOptimizationTT\n",
      "[150] kurtabela/Automatic-Sports-Match-Highlight-Generation\n",
      "[151] kweyuchesa/Hypothesis-Tests-For-all-Data-Scientists\n",
      "[152] ericayee/restfulness\n",
      "[153] asmitapoddar/Autoencoder-ATLAS\n",
      "[154] AkashRupapara/Face-Recognition-Gender-Classification-and-Emotion-Recognition\n",
      "[155] Timonzimm/poincare-embedding\n",
      "[156] NemesLaszlo/Item-Item_Collaborative_Filtering\n",
      "[157] Cinofix/graph-kernel-manifold-learning\n",
      "[158] JackKuo666/csdn_blog_code_implement\n",
      "[159] reddyprasade/Machine-Learning-Interview-Preparation\n",
      "[160] ndthapar/S-P-returns-30-year-friday-monday-correlation\n",
      "[161] nitinkumar388/-Logistic-Regression-vs-SVM-with-Titanic-Dataset\n",
      "[162] jcrdubois/CorrPower\n",
      "[163] pruhlo/Reservation_test\n",
      "[164] sidastro30/task-scheduling-heterogeneous-system\n",
      "[165] warisgill/profile-matching\n",
      "[166] DavidBraslow/Our-Class-Graph\n",
      "[167] Aishwarya-Virigineni/GREEDY-SORTING-OF-PERMUTATIONS-BY-REVERSALS\n",
      "[168] slavicYoda/Greg-s-Data-Science-sample-models-projects\n",
      "[169] MedicalImageAnalysisTutorials/ImageRegistrationTutorial\n",
      "[170] florianbeyer/SpectralIndices\n",
      "[171] upasanam20/Creative-Analysis-with-Google-Oculi\n",
      "[172] ArkadiuszWos/Regular-Expression\n",
      "[173] goyal64/Leveraging-Analytics-to-optimize-the-efficiency-of-Assembly-Line\n",
      "[174] MattBlue92/data_security_privacy_2018_2019\n",
      "[175] avakanski/Attention-Enriched-DL-Model-for-Breast-Tumor-Segmentation\n",
      "[176] zxhohai/mlp_mnist\n",
      "[177] junkal/Generate-faces-with-Variable-Autoencoder\n",
      "[178] FTEickemeyer/PLQY_analysis\n",
      "[179] tunglin55/Breast-Cancer-Detection\n",
      "[180] ashinde8/Data-Preprocessing-and-Machine-Learning\n",
      "[181] 10Academy-B6-W2/Smart-Ads-campaign-performance-analysis\n",
      "[182] Adityagrao/Poincar-Embeddings-for-Learning-Hierarchical-Representations\n",
      "[183] brain-score/brain-score\n",
      "[184] Gigabyte2408/cpu-simulator\n",
      "[185] TejasKarkera10/Regular-Expression-Based-Sentence-tokenizer\n",
      "[186] Hongyu-Li/Tumor_Detection\n",
      "[187] EricOdhiambo/Predictive-Analysis-of-Crime-Incidence-in-Kenya-based-on-SocioEconomic-Factors\n",
      "[188] sergehijo/test-rappi-DS\n",
      "[189] ateniolatobi/Differential-privacy-for-deeplearning-project\n",
      "[190] AdrianaElena/ArucoMarkers\n",
      "[191] doublelockcup/Pathology-Images-Classification\n",
      "[192] VikasNatuskar/Facial-Keypoint-Detection\n",
      "[193] osinkolu/30-Days-of-Learning\n",
      "[194] RajaRamPriyadarshi/Red-Wine-Analysis\n",
      "[195] aliicee3/LOGML2021-Learning-Latent-Geometries\n",
      "[196] ValiVuj/Chilli_Kobe_Flask_vjezba\n",
      "[197] ankitjoshi1995/Janata-Healthcare-Analytics\n",
      "[198] linhnguyen215538/Volatility-Study\n",
      "[199] worry1613/csdn-blog-recommend\n",
      "[200] kunalninave/consumer-ad-analysis\n",
      "[201] tourloukisg/ARIMA_X-SARIMA_X-Time-Series-Forecasting\n",
      "[202] sassoftware/model-management-resources\n",
      "[203] shaodiana/BreastCancerPrediction\n",
      "[204] saketd403/Visualising-Image-Classification-Models-and-Saliency-Maps\n",
      "[205] Neviya/Super-Bowl-DataAnalysis\n",
      "[206] hjfenghj/3D-point-cloud-processing\n",
      "[207] RFAD-Research-Team/breast-tumor-detection\n",
      "[208] ankit94/Brain-Network-Analysis\n",
      "[209] omkarsarde/Adversarial-Attack-on-Deep-Learning-Models\n",
      "[210] gowun/BladderCancer_AMC\n",
      "[211] arpit3043/Extractive-Text-Summerization\n",
      "[212] imatge-upc/saliency-2018-timeweight\n",
      "[213] mwilchek/Differential-Privacy-Synthetic-PII\n",
      "[214] MartheWens/Water_Resource_Management_Modelling\n",
      "[215] CJRobey/3D-Reconstruction\n",
      "[216] qusaybtoush/Texas-Wind---Turbine---Accuracy-99-\n",
      "[217] morikaglobal/melbourne_temperature_time_series_analysis\n",
      "[218] singhAbhishek16/HumanResourceManagement\n",
      "[219] imamahasane/Bladder_Cancer_Prediction\n",
      "[220] s0sasaki/ComputerVisionTechniques\n",
      "Add NB_fd84529753360225f74428be9f349a25c9c2f31bc0e43c8850dc84912f57a733\n",
      "Write to notebook_contents/NB_fd84529753360225f74428be9f349a25c9c2f31bc0e43c8850dc84912f57a733.ipynb\n",
      "Add NB_45bd6d6bfd3ba374384e30bbc6f1ae2fbfab16bc68b75226c0c5dd55a612bd55\n",
      "Write to notebook_contents/NB_45bd6d6bfd3ba374384e30bbc6f1ae2fbfab16bc68b75226c0c5dd55a612bd55.ipynb\n",
      "[221] yama-santhosh/INX_FEATURED_DATA_IABAC_Proj\n",
      "[222] leandromouralima/deep-learning\n",
      "[223] weizhiyangq/ARIMA-DEMO\n",
      "[224] RishabhGarg10/Time-Series-Analysis\n",
      "[225] ngoclesydney/Anomaly-Detection-with-Swat-Dataset\n",
      "[226] EsadSimitcioglu/Adverserial-CAPTCHA\n",
      "[227] syvail/PairE-Graph-Representation-Learning-Beyond-Node-and-Homophily\n",
      "[228] yashk7oo/Charity-ML-Predictor\n",
      "[229] tourloukisg/Python-LSTM-Univariate-Time-Series-Forecasting-\n",
      "[230] zakaryaxali/poincare_embeddings\n",
      "[231] esnet/workflow-databooks\n",
      "[232] Jrocha424/Stock-Market-Data-Preprocessing-\n",
      "[233] unza-farhat/Jawan-Pakistan_final_project_of_data_science-\n",
      "[234] ryota765/Trimap-Generation\n",
      "[235] alexafreedman/Linear-Regression-\n",
      "[236] taliaalouise/myTestRepo\n",
      "[237] uft93/Sample_Regression_Analysis\n",
      "[238] neurollero/analysis_scripts\n",
      "[239] diracdyson/Research-paper-An-overview-of-modern-day-Anomaly-Detection-in-Univariate-Time-Series\n",
      "[240] Sahrawat1/Semantic-Textual-Similarity\n",
      "[241] zachetienne/nrpytutorial\n",
      "[242] jordenpiu/Automated-traffic-Lightining-System\n",
      "[243] nitinkumar388/Iris-Dataset-with-DecisionTree-vs-Random-Forest\n",
      "[244] puririshi98/DeepNet-Visualization\n",
      "[245] dahliahadfury/automaticsummarize\n",
      "[246] JNandez/intraCorr\n",
      "[247] prasathmbalaji/Deeplearning-model-for-Speech-Disorder\n",
      "[248] anandwani/Applied-Deep-Learning\n",
      "[249] KonstantinBurkin/personalized-medicine\n",
      "[250] satoru2001/Facial_Expression_Recognition\n",
      "[251] 17Athena/Rigel\n",
      "[252] santoshc96/Health-Care---Hackathon\n",
      "[253] Reemr/Cancer-detection\n",
      "[254] amitsanger3/SpecularityRemoval\n",
      "[255] microsoft/CodeMixed-Text-Generator\n",
      "[256] kinganupamdutta27/Voice-Assistant-using-Python\n",
      "[257] cbanuelos/Structural_Brain_Network_Topology\n",
      "[258] dimabey/aruco_pose\n",
      "[259] maxboels/Predicting-Breast-Cancer-Malignancy-from-X-rays\n",
      "[260] birnbaum/simple-benchmark\n",
      "[261] charantanuj/GREEDY-SORTING-OF-PERMUTATIONS-BY-REVERSALS\n",
      "[262] curiousily/Deep-Learning-For-Hackers\n",
      "[263] muratxs/GeneExpression_HighRisk_BladderCancerML\n",
      "[264] staschistyakov/Deep_Learning_Wireless_Networks\n",
      "[265] ikiraschielke/multi-parent-poincare-embeddings\n",
      "[266] KlinterAI/image-recognition-with-privacy\n",
      "[267] DU0930/Forest-Cover-Type-Prediction\n",
      "[268] polive106/Time-Series-Forecasting-DeepAR\n",
      "[269] LeaBresson/Poincare-embeddings\n",
      "[270] NitinCJ/Breast-cancer-severity-detection\n",
      "[271] jwu047/data_journalism\n",
      "[272] Saijoshitha/Bio-medical-system-engineering-and-automation\n",
      "[273] yurayli/nn-visualization\n",
      "[274] Yuze-Li/Mass-Spectrometry-plus-Machine-Learning\n",
      "[275] saikrishnaneelam/online-shopper-intention-\n",
      "[276] QwertyJacob/e2d4qn_vcdn_sfc_deployment\n",
      "[277] YEZIQM/Node2Vec_Subject_similarity\n",
      "[278] sammy-w/visual_saliency\n",
      "[279] WM-SEMERU/SecureReqNet\n",
      "[280] alexanderhowada/monitor_system\n",
      "[281] harshapakki/linear_regression_model\n",
      "[282] Aniket-Thopte/Probabilistic-Electric-Load-Forecasting-using-Gradient-Boosting-Regressor\n",
      "[283] chenxd2/Detecting-Cancer-Metastases-on-Gigapixel-Pathology-Images\n",
      "[284] ericlrf/rul\n",
      "[285] CarlosLiverani/PrognosticRiskOfDeathUsingTreeModels\n",
      "[286] basuraj3328/Complaint-Analysis\n",
      "[287] cf814/dynamicVehRouting\n",
      "[288] irmadong/Cancer_Detection_Gigapixel_Images\n",
      "[289] saberbf/DeepEEG\n",
      "[290] ZhaomingKong/MGNets\n",
      "[291] YukiChen-yuxin/Design-and-implementation-of-a-task-based-Q-A-system-based-on-TCM-knowledge-graph\n",
      "[292] CVUsers/Fire-Detect-by-YoloV5\n",
      "[293] armanr99/NS2-TCP-Congestion-Control\n",
      "[294] ashtiv/Stock-Prediction\n",
      "[295] tahaShm/congestion-control\n",
      "[296] AnkurNapa/linear-regression-model-for-the-prediction-of-demand-for-shared-bikes\n",
      "[297] arishp/tamil_vowels_recognition_cnn_colab\n",
      "[298] GAOJinmei/Prediction-Subtype-of-Bladder-Cancer-with-MLP-and-CNN\n",
      "[299] I-Gayatri-ENG19CS0122/SIGN-LANGUAGE-DETECTION-USING-ACTION-RECOGNITION\n",
      "[300] afiliot/Bayesian-Personalization-Of-A-Tumor-Growth-Model\n",
      "[301] rutwikd95/Detecting-Cancer-Metastases-on-Gigapixel-Pathology-Images\n",
      "[302] jeremite/Simple-Music-Recommendation\n",
      "[303] j-wilhelm/Automatic_description_generation\n",
      "[304] netsatsawat/HR-Analytics\n",
      "[305] Aditya-cmg/Sales-Conversion-Optimization\n",
      "[306] zvdas/App-Rating-Prediction\n",
      "[307] ayatullah2018/-neural-networks-for-regression-by-deep-learning\n",
      "[308] Gabe-Maja/Load-Shortfall-Regression-Project\n",
      "[309] OuyangWenyu/aqualord\n",
      "[310] cnlab/ConnectivityExclusionSocialNetworkPNAS\n",
      "[311] HanXiaoyang/naive_bayes\n",
      "[312] saimaheshkothagulla/Numpy-module\n",
      "[313] captain-pool/HEP_Atlas_AutoEncoder\n",
      "[314] jiwuxuan/yolov5-master0\n",
      "[315] WadiiBoulila/Hybrid-Privacy-Preserving-Deep-Learning\n",
      "[316] Felipalds/computer-architecture-and-organization\n",
      "[317] jasonsheu/snapchat-ads\n",
      "[318] aish27/facial-keypoint-detection\n",
      "[319] pascalgerig/privacy_and_data_security\n",
      "[320] ruisizhang123/Pseudo-Relevance-Feedback\n",
      "[321] HenryNebula/camelyon16_mini\n",
      "[322] JiashiSong/Microsoft-Malware-Prediction\n",
      "[323] MrBriit/FLASK-End-to-end-Zomato-Restaurant-Price-Prediction-and-Deployment\n",
      "[324] simranmakandar/Predicting-Credit-Card-Approvals\n",
      "[325] brundha30/Practice-Problems-Regular-Expression\n",
      "[326] Melo-Wang/Deep-Learning-on-Point-Cloud-of-Aerospace-Components-for-3D-Classification\n",
      "[327] dhwani77/Using-MapReduce-on-amazon-reviews\n",
      "[328] junfish/MGNet\n",
      "[329] brettbj/PoincareEmbeddings\n",
      "[330] Nature40/Sensorboxes-Bat-Cave\n",
      "[331] VincentBrunner/spectrum-regression-\n",
      "[332] amw14/NeuroDet\n",
      "[333] fahriialfiansyah/Analysis-Super-Bowl-Data\n",
      "[334] OmarEhab007/Facial__Keypoint_Detection\n",
      "[335] AI-14/Video-Captioning-For-Arabic-Sign-Language-Recognition-At-Sentence-Level\n",
      "[336] eugenbobrov/Power-Allocation-Algorithms-for-Massive-MIMO-Systems-with-Multi-Antenna-Users\n",
      "[337] luckyos-code/DP-X-COVID\n",
      "[338] seppia978/A-Visualising-Image-Classification-Models-and-Saliency-Maps-Implementation\n",
      "[339] Anugataa/Lead-Scoring_-Logistic-Regression\n",
      "[340] maulik96/tumor-detection\n",
      "[341] HowieHye/Attention-Enriched-Deep-Learning-Model-for-Breast-Tumor-Segmentation\n",
      "[342] mattConn/differential-geometry-exercises\n",
      "[343] haochen23/bladderMachineLearning\n",
      "[344] migueleps/RegularAsymptomaticTesting\n",
      "[345] nomcomm/BrainConnectivitySocialNetwork_PNAS\n",
      "[346] samthegliderpilot/PythonEquations2Orbits\n",
      "[347] alexcaselli/Federated-Learning-for-Human-Mobility-Models\n",
      "[348] shubham9793/Linear-Regression-Model-in-Machine-Learning\n",
      "[349] xianchen2/Text_Retrieval_BM25\n",
      "[350] IoTcloudServe/Smart-Mobility-Chula\n",
      "[351] BrijeshYadav001st/CPU-RAM-scratch\n",
      "[352] SingingData/TabularDataPreprocessing\n",
      "[353] manuelpt49/Development-and-Validation-of-Linear-Regression-Equations-to-Obtain-SPPB-Scores-\n",
      "[354] 1superman/SMP2017CSDN-\n",
      "[355] AI-MEGHA/Recommendation-Medicines-by-using-a-review\n",
      "[356] solanki1993/Breast_cancer_classification-_using-_ML\n",
      "[357] nrishabh/atlas-autoencoder\n",
      "[358] priscilla100/ensemble_IDS\n",
      "[359] Harshal-Jaiswal/CharityML\n",
      "[360] VidhanA-01/Visual-Saliency\n",
      "[361] AlanPalomino/covid19_phase_spaces\n",
      "[362] ferasalnaem/Master-thesis\n",
      "[363] abhay-lal/Alveoli\n",
      "[364] 2724170230/Optimization-Model-for-Emergency-Shelter-Location-Selection\n",
      "[365] GGroup11/CapSecure\n",
      "[366] lilfetz22/Reddit_sentiment_analysis\n",
      "[367] rcz7795/Starbucks-Offers-Advertisement-Data-Analysis\n",
      "[368] JessicaAndrew/Final_year_project\n",
      "[369] annstrange/breast-cancer-cnn\n",
      "[370] jckantor/STN-Scheduler\n",
      "[371] nitinkaushik01/Various_ways_to_read_the_different_types_of_Data_Python\n",
      "[372] vr620/Adaptive_traffic_light_system\n",
      "[373] bipinkc19/visualizing_cnn\n",
      "[374] siddhartha4u2c/TimeSeries-Data-Analysis\n",
      "[375] mpindaro/brain-network-analysis\n",
      "[376] pltrung/Mobiground-GA-Analysis\n",
      "[377] maliknandini/Detecting-Cancer-in-Gigapixel-Pathology-Images\n",
      "[378] Birbalk99/House-Loan-Data-Analysis\n",
      "[379] ahmadreza1376/Task_scheduling\n",
      "[380] gomathy-divakar/Student-Performance-Analysis\n",
      "[381] subnets/EpiNetReorgChronicRNS\n",
      "[382] andrewni4313/GeneticAD\n",
      "[383] ShuheiKuriki/Trial_Poincare_embeddings\n",
      "[384] abdelaziz-jaddi/segmentation-of-regions-with-glomeruli-in-human-kidney-tissue-images-across-different-tissue\n",
      "[385] KallaDivyachandrika/VISUALIZATION-FOR-SOLVING-NON-IMAGE-PROBLEMS-AND-SALIENCY-MAPPING\n",
      "[386] lucylow/CERN_HEP_Autoencoder\n",
      "[387] yog3shmandg3/Auto-Hybrid-Scaling-for-VNFs\n",
      "[388] rubato-yeong/med_img_registration\n",
      "[389] mrmonroy/AuxTel_eqw\n",
      "[390] Satishkumar0651/facial-keypoint-identification\n",
      "[391] Irvinglove/chatbot-retrieval\n",
      "[392] JoeXinfa/tcpcc\n",
      "[393] videetnimsarkar21/Visual_Saliency\n",
      "[394] kranthi419/Effective-Deep-Learning-approach-based-on-VGG-Mini-Architecture-for-Iris-Recognition\n",
      "[395] gzl9386/Bladder-Cancer\n",
      "[396] junkal/Generate-Anime-Face-using-Variable-Autoencoder\n",
      "[397] swaingotnochill/AtlasAutoEncoder\n",
      "[398] Mrityunjaydeepak/Congestion-detection-using-fuzzy-logic\n",
      "[399] PSNAppz/NFV_ML_Dev\n",
      "[400] wh2353/Detect-tumor-in-gigapixel-pathology-images\n",
      "[401] neulab/code-bert-score\n",
      "[402] hajarmerbouh/Cybersecurity-Knowledge-graph\n",
      "[403] bxc8802/Deepfake-Synthetic-Image-Detection\n",
      "[404] aadityachapagain/Visualizing_CNN_filters-and-Saliency_maps\n",
      "[405] Uthso66/Thesis\n",
      "[406] eroblin/Poincare_Embeddings\n",
      "[407] valentynbez/bimanual-palpation-bladder-cancer\n",
      "[408] soufianemostafi/Speech-Emotion-Recognition\n",
      "[409] siddharthsonetta/Finding-Donors-for-Charity\n",
      "[410] Gkao03/Saliency-Map-Visualization\n",
      "[411] mibillen/Subduction-Dynamics-Tools\n",
      "[412] KimoonRyu/BreastCancer\n",
      "[413] liamcarroll/music-recsys\n",
      "[414] chandrimahere/Automated-Report-Card-Generation\n",
      "403 {\"message\": \"API rate limit exceeded for user ID 15682451.\", \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}\n",
      "Rate limit: RateLimit(core=Rate(reset=2023-04-22 13:43:32, remaining=0, limit=5000))\n",
      "Rate remaining: 0\n",
      "Rate reset time: 2023-04-22 15:43:32+02:00\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitExceededException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m: \n\u001b[0;32m---> 18\u001b[0m     repo \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49mget_repo(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00muser\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrepo\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m     contents \u001b[39m=\u001b[39m repo\u001b[39m.\u001b[39mget_contents(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vre/lib/python3.8/site-packages/github/MainClass.py:321\u001b[0m, in \u001b[0;36mGithub.get_repo\u001b[0;34m(self, full_name_or_id, lazy)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[39mreturn\u001b[39;00m Repository\u001b[39m.\u001b[39mRepository(\n\u001b[1;32m    319\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__requester, {}, {\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m: url}, completed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m headers, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__requester\u001b[39m.\u001b[39;49mrequestJsonAndCheck(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url)\n\u001b[1;32m    322\u001b[0m \u001b[39mreturn\u001b[39;00m Repository\u001b[39m.\u001b[39mRepository(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__requester, headers, data, completed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vre/lib/python3.8/site-packages/github/Requester.py:398\u001b[0m, in \u001b[0;36mRequester.requestJsonAndCheck\u001b[0;34m(self, verb, url, parameters, headers, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequestJsonAndCheck\u001b[39m(\u001b[39mself\u001b[39m, verb, url, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__check(\n\u001b[1;32m    399\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequestJson(\n\u001b[1;32m    400\u001b[0m             verb, url, parameters, headers, \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__customConnection(url)\n\u001b[1;32m    401\u001b[0m         )\n\u001b[1;32m    402\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/vre/lib/python3.8/site-packages/github/Requester.py:423\u001b[0m, in \u001b[0;36mRequester.__check\u001b[0;34m(self, status, responseHeaders, output)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m status \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__createException(status, responseHeaders, output)\n\u001b[1;32m    424\u001b[0m \u001b[39mreturn\u001b[39;00m responseHeaders, output\n",
      "\u001b[0;31mRateLimitExceededException\u001b[0m: 403 {\"message\": \"API rate limit exceeded for user ID 15682451.\", \"documentation_url\": \"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(e)\n\u001b[1;32m     24\u001b[0m get_rate_limit_info(g) \n\u001b[0;32m---> 25\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Retrieve the repository\n",
    "for i, repo_url in enumerate(repo_urls): \n",
    "    parsed_url = urlparse(repo_url)\n",
    "    path_parts = parsed_url.path.split('/')\n",
    "    user = path_parts[1]\n",
    "    repo = path_parts[2]\n",
    "\n",
    "    print(f'[{i}] {user}/{repo}')\n",
    "    record = {\n",
    "        'repo_url': repo_url, \n",
    "        'downloaded': True\n",
    "    }\n",
    "    if check_record_in_csv(REPO_DOWNLOAD_LOG, record, 'repo_url'): \n",
    "        # print(f'{repo_url} already downloaded!')\n",
    "        continue\n",
    "    else: \n",
    "        try: \n",
    "            repo = g.get_repo(f\"{user}/{repo}\")\n",
    "            contents = repo.get_contents('')\n",
    "            traverse_contents(contents, NOTEBOOK_CONTENT_PATH)\n",
    "            add_row_csv(REPO_DOWNLOAD_LOG, [repo_url, True])\n",
    "        except RateLimitExceededException as e: \n",
    "            print(e)\n",
    "            get_rate_limit_info(g) \n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f67b90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce4582f-71e4-405f-95f7-d8c80685681a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of .ipynb files in notebook_contents: 5618\n"
     ]
    }
   ],
   "source": [
    "# Count the number of notebooks\n",
    "def count_ipynb_files(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "# Example usage\n",
    "directory = 'notebook_contents'\n",
    "count = count_ipynb_files(directory)\n",
    "print(f'Number of .ipynb files in {directory}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc35de2-96f9-4cb0-a93f-7cc112d35590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
