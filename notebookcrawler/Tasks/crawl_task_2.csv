_id,query,searched,downloaded
6387a608727ddf9f05e7ec64,Deep Boltzmann Machine,19,-1
6387a608727ddf9f05e7ec68,SReLU,17,-1
6387a608727ddf9f05e7ec6a,Differentiable NAS,8,-1
6387a608727ddf9f05e7ec6c,LCC,174,-1
6387a608727ddf9f05e7ec6e,Poly-CAM,16,-1
6387a608727ddf9f05e7ec72,"Momentumized, adaptive, dual averaged gradient",2,-1
6387a608727ddf9f05e7ec74,STAC,160,-1
6387a608727ddf9f05e7ec78,ERNIE-GEN,2,-1
6387a608727ddf9f05e7ec7a,Locally-Grouped Self-Attention,11,-1
6387a608727ddf9f05e7ec7e,Modular Interactive VOS,2,-1
6387a608727ddf9f05e7ec80,Adaptively Spatial Feature Fusion,1,-1
6387a608727ddf9f05e7ec82,Reversible Residual Block,3,-1
6387a608727ddf9f05e7ec84,Laplacian Pyramid,15,-1
6387a608727ddf9f05e7ec86,MPRNet,1,-1
6387a608727ddf9f05e7ec8c,CenterTrack,1,-1
6387a608727ddf9f05e7ec90,Orthogonal Regularization,47,-1
6387a608727ddf9f05e7ec92,HGS,15,-1
6387a608727ddf9f05e7ec94,ACGPN,18,-1
6387a608727ddf9f05e7ec96,SGDW,6,-1
6387a608727ddf9f05e7ec9a,Informative Sample Mining Network,23,-1
6387a608727ddf9f05e7ec9c,COLA,176,-1
6387a608727ddf9f05e7eca0,Inception-ResNet-v2-C,31,-1
6387a608727ddf9f05e7eca4,lda2vec,13,-1
6387a608727ddf9f05e7eca6,MnasNet,24,-1
6387a608727ddf9f05e7ecaa,Detr,76,-1
6387a608727ddf9f05e7ecac,Class-Attention in Image Transformers,53,-1
6387a608727ddf9f05e7ecae,High-resolution Deep Convolutional Generative Adversarial Networks,40,-1
6387a608727ddf9f05e7ecb0,DeepLab,123,-1
6387a608727ddf9f05e7ecb6,Gradient Checkpointing,65,-1
6387a608727ddf9f05e7ecb8,Inception-ResNet-v2,76,-1
6387a608727ddf9f05e7ecba,Feedback Memory,106,-1
6387a608727ddf9f05e7ecbc,SANet,8,-1
6387a608727ddf9f05e7ecbe,Attention with Linear Biases,59,-1
6387a608727ddf9f05e7ecc0,PDC,36,-1
6387a608727ddf9f05e7ecc2,Introspective Adversarial Network,2,-1
6387a608727ddf9f05e7ecc4,U2-Net,100,-1
6387a608727ddf9f05e7ecc6,Unsupervised Deep Manifold Attributed Graph Embedding,2,-1
6387a608727ddf9f05e7ecc8,MushroomRL,1,-1
6387a608727ddf9f05e7ecca,XCiT,20,-1
6387a608727ddf9f05e7eccc,Visual Parsing,115,-1
6387a608727ddf9f05e7ecce,Minimum Description Length,122,-1
6387a608727ddf9f05e7ecd0,Gaussian Affinity,120,-1
6387a608727ddf9f05e7ecd2,Deep Belief Network,22,-1
6387a608727ddf9f05e7ecd4,Attention Mesh,21,-1
6387a608727ddf9f05e7ecd6,Adaptive Loss,101,-1
6387a608727ddf9f05e7ecd8,BS-Net,124,-1
6387a608727ddf9f05e7ecda,ProxylessNAS,2,-1
6387a608727ddf9f05e7ecdc,Distributed Shampoo,5,-1
6387a608727ddf9f05e7ecde,VERtex Similarity Embeddings,8,-1
6387a608727ddf9f05e7ece0,Gated Graph Sequence Neural Networks,25,-1
6387a608727ddf9f05e7ece2,Global-Local Attention,37,-1
6387a608727ddf9f05e7ece4,Res2Net,13,-1
6387a608727ddf9f05e7ecea,CPN,19,-1
6387a608727ddf9f05e7ecec,PASE+,52,-1
6387a608727ddf9f05e7ecf0,ViLT,4,-1
6387a608727ddf9f05e7ecf6,Linear Warmup With Cosine Annealing,12,-1
6387a608727ddf9f05e7ecf8,MViT,6,-1
6387a608727ddf9f05e7ecfa,Sigmoid Activation,94,-1
6387a608727ddf9f05e7ecfc,MAML,22,-1
6387a609727ddf9f05e7ef32,RMSProp,200,-1
6387a609727ddf9f05e7ef60,Canvas Method,200,-1
6387a609727ddf9f05e7ef62,SlowMo,2,-1
6387a609727ddf9f05e7ef6e,Inception-v3,200,-1
6387a609727ddf9f05e7ef78,Seq2Seq,200,-1
6387a609727ddf9f05e7ef7a,Directional Sparse Filtering,7,-1
6387a609727ddf9f05e7ef82,HypE,200,-1
6387a609727ddf9f05e7ef84,Unbiased Online Recurrent Optimization,2,-1
6387a609727ddf9f05e7ef86,MoCo v2,9,-1
6387a609727ddf9f05e7ef8a,Fourier Contour Embedding,3,-1
6387a609727ddf9f05e7ef8c,Detailed Expression Capture and Animation,7,-1
6387a609727ddf9f05e7ef8e,MuZero,3,-1
6387a609727ddf9f05e7ef90,Independent Component Analysis,200,-1
6387a609727ddf9f05e7ef92,LAMA,200,-1
6387a609727ddf9f05e7ef94,Gaussian Error Linear Units,200,-1
6387a609727ddf9f05e7ef96,GPT-2,200,-1
6387a609727ddf9f05e7ef98,IQL,10,-1
6387a609727ddf9f05e7ef9a,SaBN,2,-1
6387a609727ddf9f05e7ef9c,GMVAE,1,-1
6387a609727ddf9f05e7ef9e,CANINE,77,-1
6387a609727ddf9f05e7efa0,ALIS,200,-1
6387a609727ddf9f05e7efa2,FeatureNMS,0,-1
6387a609727ddf9f05e7efa4,SEED RL,200,-1
6387a609727ddf9f05e7efa6,RotNet,5,-1
6387a609727ddf9f05e7efa8,Polyak Averaging,3,-1
6387a609727ddf9f05e7efaa,PixelShuffle,43,-1
6387a609727ddf9f05e7efac,Mixer Layer,29,-1
6387a609727ddf9f05e7efae,Single-Headed Attention,73,-1
6387a609727ddf9f05e7efb0,Relation-aware Global Attention,61,-1
6387a609727ddf9f05e7efb2,Test-time Local Converter,36,-1
6387a609727ddf9f05e7efb4,Large-scale Information Network Embedding,200,-1
6387a609727ddf9f05e7efb6,Pixel Recurrent Neural Network,133,-1
6387a609727ddf9f05e7efb8,Global Context Block,200,-1
6387a609727ddf9f05e7efba,Weight Tying,35,-1
6387a609727ddf9f05e7efbc,ELU,200,-1
6387a609727ddf9f05e7efbe,PELU,12,-1
6387a609727ddf9f05e7efc0,Hi-LANDER,3,-1
6387a609727ddf9f05e7efc2,NCL,148,-1
6387a609727ddf9f05e7efc4,Unitary RNN,0,-1
6387a609727ddf9f05e7efc6,Fishr,2,-1
6387a609727ddf9f05e7efc8,Negative Face Recognition,200,-1
6387a609727ddf9f05e7efca,Phish: A Novel Hyper-Optimizable Activation Function,0,-1
6387a609727ddf9f05e7efcc,Learning to Match,200,-1
6387a609727ddf9f05e7efce,Conditional Relation Network,40,-1
6387a609727ddf9f05e7efd0,RE-NET,200,-1
6387a609727ddf9f05e7efd2,SqueezeNeXt,1,-1
6387a609727ddf9f05e7efd4,DMA,191,-1
6387a609727ddf9f05e7efd6,PointNet,42,-1
6387a609727ddf9f05e7efd8,Conditional Random Field,200,-1
6387a609727ddf9f05e7efda,Self-regularizing Boundary Time and Amplitude Warping,0,-1
6387a609727ddf9f05e7efdc,E-MBConv,8,-1
6387a609727ddf9f05e7efde,GAN Least Squares Loss,44,-1
6387a609727ddf9f05e7efe0,Channel & Spatial attention,188,-1
6387a609727ddf9f05e7efe2,HITNet,0,-1
6387a609727ddf9f05e7efe4,Neural Additive Model,200,-1
