_id,query,searched,downloaded
63876442727ddf9f05e58d8d,Pre-trained Transliterated Embeddings for Indian Languages,-1,-1
63876442727ddf9f05e58d8f,Western Mediterranean Wetlands Birds - Version 2,-1,-1
63876442727ddf9f05e58d91,RITE,-1,-1
63876442727ddf9f05e58d93,3D cross-source point cloud registration dataset,-1,-1
63876442727ddf9f05e58d95,HYPERVIEW,-1,-1
63876442727ddf9f05e58d97,Multilingual Reuters,-1,-1
63876442727ddf9f05e58d99,Kuzushiji-49,-1,-1
63876442727ddf9f05e58d9b,CVEfixes,-1,-1
63876442727ddf9f05e58d9d,SketchyVR,-1,-1
63876442727ddf9f05e58d9f,Multilingual Persuasion Detection,-1,-1
63876442727ddf9f05e58da1,StyleGAN-Human,-1,-1
63876442727ddf9f05e58da3,Boxy Vehicles Dataset,-1,-1
63876442727ddf9f05e58da5,CORRONA CERTAIN,-1,-1
63876442727ddf9f05e58da7,TOSCA,-1,-1
63876442727ddf9f05e58da9,DAVIS-585,-1,-1
63876442727ddf9f05e58dab,Crisscrossed Captions,-1,-1
63876442727ddf9f05e58dad,The Stack,-1,-1
63876442727ddf9f05e58daf,Abstract Meaning Representation,-1,-1
63876442727ddf9f05e58db1,VAST Absorption,-1,-1
63876442727ddf9f05e58db3,EXEQ-300k,-1,-1
63876442727ddf9f05e58db5,Controlled On/Off Loads Library,-1,-1
63876442727ddf9f05e58db7,"4,788 images Human Facial Skin Defects Data",-1,-1
63876442727ddf9f05e58db9,ADNI,-1,-1
63876442727ddf9f05e58dbb,HEV-I,-1,-1
63876442727ddf9f05e58dbd,Kvasir,-1,-1
63876442727ddf9f05e58dbf,AwA2,-1,-1
63876442727ddf9f05e58dc1,Building and Using Comparable Corpora,-1,-1
63876442727ddf9f05e58dc3,Visual Relationship Detection Dataset,-1,-1
63876442727ddf9f05e58dc5,Google Landmarks,-1,-1
63876442727ddf9f05e58dc7,KITTI'15 MSplus,-1,-1
63876442727ddf9f05e58dc9,Slashdot,-1,-1
63876442727ddf9f05e58dcb,XSum,-1,-1
63876442727ddf9f05e58dcd,DREAM,-1,-1
63876442727ddf9f05e58dcf,“Visible” Physical Commonsense Knowledge,-1,-1
63876442727ddf9f05e58dd1,FSD50K,-1,-1
63876442727ddf9f05e58dd3,Clinical Diagnosis Normalization Dataset,-1,-1
63876442727ddf9f05e58dd5,TUT Acoustic Scenes 2017,-1,-1
63876442727ddf9f05e58dd7,ABC Dataset,-1,-1
63876442727ddf9f05e58dd9,Brown University Stylus Handwriting,-1,-1
63876442727ddf9f05e58ddb,Sony-TAu Realistic Spatial Soundscapes 2022,-1,-1
63876442727ddf9f05e58ddd,Multi-Dimensional Gender Bias Datasets,-1,-1
63876442727ddf9f05e58ddf,CLEAR,-1,-1
63876442727ddf9f05e58de1,PRED18: Predator/Prey DAVIS Dataset,-1,-1
63876442727ddf9f05e58de3,Portrait Photo Retouching dataset,-1,-1
63876442727ddf9f05e58de5,Peer to Peer Hate,-1,-1
63876442727ddf9f05e58de7,G1020,-1,-1
63876442727ddf9f05e58de9,Mining in Ethereum,-1,-1
63876442727ddf9f05e58deb,Identity-Centric and Fine-Grained Person Description Dataset,-1,-1
63876442727ddf9f05e58ded,Hypersim,-1,-1
63876442727ddf9f05e58def,OpeReid,-1,-1
63876442727ddf9f05e58df1,895 Fire Videos Data,-1,-1
63876442727ddf9f05e58df3,Complementary Commonsense,-1,-1
63876442727ddf9f05e58df5,MOBIO,-1,-1
63876442727ddf9f05e58df7,Knowledge-Enriched Task-Oriented Dialogue,-1,-1
63876442727ddf9f05e58df9,Video Storytelling,-1,-1
63876442727ddf9f05e58dfb,SPEECH-COCO,-1,-1
63876442727ddf9f05e58dfd,MUSIC,-1,-1
63876442727ddf9f05e58dff,AnlamVer,-1,-1
63876442727ddf9f05e58e01,Reddit Norm Violations,-1,-1
63876442727ddf9f05e58e03,KP20k,-1,-1
63876442727ddf9f05e58e05,IIRC,-1,-1
63876442727ddf9f05e58e07,DEFT Corpus,-1,-1
63876442727ddf9f05e58e09,Grasp Affordance,-1,-1
63876442727ddf9f05e58e0b,TruthfulQA,-1,-1
63876442727ddf9f05e58e0d,EPIE,-1,-1
63876442727ddf9f05e58e0f,Stickers,-1,-1
63876442727ddf9f05e58e11,pathbased,-1,-1
63876442727ddf9f05e58e13,BReAst Carcinoma Subtyping,-1,-1
63876442727ddf9f05e58e15,Kuzushiji-Kanji,-1,-1
63876442727ddf9f05e58e17,HOPE-Image,-1,-1
63876442727ddf9f05e58e19,ASIRRA,-1,-1
63876442727ddf9f05e58e1b,HoaxItaly,-1,-1
63876442727ddf9f05e58e1d,SWSR,-1,-1
63876442727ddf9f05e58e1f,Eduge,-1,-1
63876442727ddf9f05e58e21,Spoken-SQuAD,-1,-1
63876442727ddf9f05e58e23,"ASC (TIL, 19 tasks)",-1,-1
63876442727ddf9f05e58e25,QASC,-1,-1
63876442727ddf9f05e58e27,Contextualised Polyseme Word Sense Dataset v2,-1,-1
63876442727ddf9f05e58e29,Financial Opinion Mining and Question Answering,-1,-1
63876442727ddf9f05e58e2b,Ocean Drifters,-1,-1
63876442727ddf9f05e58e2d,A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines,-1,-1
63876442727ddf9f05e58e2f,Get it #OffMyChest,-1,-1
63876442727ddf9f05e58e31,KAIST-Radar,-1,-1
63876442727ddf9f05e58e33,ELAS,-1,-1
63876442727ddf9f05e58e35,Multi-Sentence Reading Comprehension,-1,-1
63876442727ddf9f05e58e37,Cornell (60%/20%/20% random splits),-1,-1
63876442727ddf9f05e58e39,EDUVSUM,-1,-1
63876442727ddf9f05e58e3b,Dongguk Body-based Person Recognition Database (DBPerson-Recog-DB1),-1,-1
63876442727ddf9f05e58e3d,Algebra Question Answering with Rationales,-1,-1
63876442727ddf9f05e58e3f,CoVaxLies v1,-1,-1
63876442727ddf9f05e58e41,Large-scale Chinese Question Matching Corpus,-1,-1
63876442727ddf9f05e58e43,The 4th China Physiological Signal Challenge 2021,-1,-1
63876442727ddf9f05e58e45,MR Movie Reviews,-1,-1
63876442727ddf9f05e58e47,Multiple Object Tracking 17,-1,-1
63876442727ddf9f05e58e49,NTPairs,-1,-1
63876442727ddf9f05e58e4b,SciFact,-1,-1
63876442727ddf9f05e58e4d,Cross-Lingual Transfer Evaluation of Multilingual Encoders,-1,-1
63876442727ddf9f05e58e4f,PIQA,-1,-1
63876442727ddf9f05e58e51,Freebase-122,-1,-1
63876442727ddf9f05e58e53,MinneApple,-1,-1
63876442727ddf9f05e58e55,E-GMD,-1,-1
63876442727ddf9f05e58e57,Multiface,-1,-1
63876442727ddf9f05e58e59,CATS,-1,-1
63876442727ddf9f05e58e5b,Dirty-MNIST,-1,-1
63876442727ddf9f05e58e5d,CHIP-CDN,-1,-1
63876442727ddf9f05e58e5f,KADID-10k,-1,-1
63876442727ddf9f05e58e61,227 Hours - Italian Speaking English Speech Data by Mobile Phone,-1,-1
63876442727ddf9f05e58e63,Face Expression Recognition Plus dataset,-1,-1
63876442727ddf9f05e58e65,ROSTD,-1,-1
63876442727ddf9f05e58e67,Background Dataset - 20k,-1,-1
63876442727ddf9f05e58e69,Tracking the Trackers,-1,-1
63876442727ddf9f05e58e6b,Multilingual Quality Estimation and Automatic Post-editing Dataset,-1,-1
63876442727ddf9f05e58e6d,Purpose-driven Affordance Dataset,-1,-1
63876442727ddf9f05e58e6f,RoboCupSimData,-1,-1
63876442727ddf9f05e58e71,MUlti-Shot EventS,-1,-1
63876442727ddf9f05e58e73,ROF,-1,-1
63876442727ddf9f05e58e75,OSCD,-1,-1
63876442727ddf9f05e58e77,Neural Latents Benchmark,-1,-1
63876442727ddf9f05e58e79,RC-49,-1,-1
63876442727ddf9f05e58e7b,Color BSD68,-1,-1
63876442727ddf9f05e58e7d,H-DIBCO 2016,-1,-1
63876442727ddf9f05e58e7f,NAFLD pathology and healthy tissue samples,-1,-1
63876442727ddf9f05e58e81,ML-CB,-1,-1
63876442727ddf9f05e58e83,NERGRIT Corpus,-1,-1
63876442727ddf9f05e58e85,FoodSeg103,-1,-1
63876442727ddf9f05e58e87,Procedural Human Action Videos,-1,-1
63876442727ddf9f05e58e89,MOD,-1,-1
63876442727ddf9f05e58e8b,Drone Tracking,-1,-1
63876442727ddf9f05e58e8d,Colossal Clean Crawled Corpus,-1,-1
63876442727ddf9f05e58e8f,MFAQ,-1,-1
63876442727ddf9f05e58e91,Berlin Database of Emotional Speech,-1,-1
63876442727ddf9f05e58e93,Oxford Buildings,-1,-1
63876442727ddf9f05e58e95,Social Bias Inference Corpus,-1,-1
63876442727ddf9f05e58e97,CCGbank,-1,-1
63876442727ddf9f05e58e99,Cooperative Driving Dataset,-1,-1
63876442727ddf9f05e58e9b,PAGE,-1,-1
63876442727ddf9f05e58e9d,VALUE,-1,-1
63876442727ddf9f05e58e9f,OADAT: Experimental and Synthetic Clinical Optoacoustic Data for Standardized Image Processing,-1,-1
63876442727ddf9f05e58ea1,RAVEN-FAIR,-1,-1
63876442727ddf9f05e58ea3,WMT19 Metrics Task,-1,-1
63876442727ddf9f05e58ea5,SKM-TEA,-1,-1
63876442727ddf9f05e58ea7,TimeTravel,-1,-1
63876442727ddf9f05e58ea9,SHREC 2016 TRACK: PARTIAL MATCHING OF DEFORMABLE SHAPES,-1,-1
63876442727ddf9f05e58eab,CoNaLa,-1,-1
63876442727ddf9f05e58ead,NTU RGB+D 2D,-1,-1
63876442727ddf9f05e58eaf,Incidents1M,-1,-1
63876442727ddf9f05e58eb1,Extended MNIST,-1,-1
63876442727ddf9f05e58eb3,A large-scale high-resolution outdoor stereo dataset,-1,-1
63876442727ddf9f05e58eb5,CVIT PIB,-1,-1
63876442727ddf9f05e58eb7,Ninapro DB5 - 10 Intact Subjects - Double Myo Armband,-1,-1
63876442727ddf9f05e58eb9,GIGO revisited: ML publications' approaches to training data,-1,-1
63876442727ddf9f05e58ebb,QUVA Repetition,-1,-1
63876442727ddf9f05e58ebd,Track Long and Prosper,-1,-1
63876442727ddf9f05e58ebf,WITS,-1,-1
63876442727ddf9f05e58ec1,Wikipedia Generation,-1,-1
63876442727ddf9f05e58ec3,Multi-scene Aerial Image,-1,-1
63876442727ddf9f05e58ec5,RIT-18,-1,-1
63876442727ddf9f05e58ec7,FSDKaggle2019,-1,-1
63876442727ddf9f05e58ec9,REDDIT-5K,-1,-1
63876442727ddf9f05e58ecb,MDIA,-1,-1
63876442727ddf9f05e58ecd,VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena,-1,-1
63876442727ddf9f05e58ecf,MJU-Waste,-1,-1
63876442727ddf9f05e58ed1,Semantic Scholar Network,-1,-1
63876442727ddf9f05e58ed3,PARANMT-50M,-1,-1
63876442727ddf9f05e58ed5,PMC-SA,-1,-1
63876442727ddf9f05e58ed7,TUM-GAID,-1,-1
63876442727ddf9f05e58ed9,DeepSport Dataset,-1,-1
63876442727ddf9f05e58edb,GAMMA Challenge,-1,-1
63876442727ddf9f05e58edd,VQG,-1,-1
63876442727ddf9f05e58edf,BBBC041,-1,-1
63876442727ddf9f05e58ee1,Pseudocode-to-Code,-1,-1
63876442727ddf9f05e58ee3,EXTREME CLASSIFICATION,-1,-1
63876442727ddf9f05e58ee5,San Francisco Park Evaluation,-1,-1
63876442727ddf9f05e58ee7,WebUAV-3M,-1,-1
63876442727ddf9f05e58ee9,Pan+ChiPhoto,-1,-1
63876442727ddf9f05e58eeb,The Uzbek Wordnet,-1,-1
63876442727ddf9f05e58eed,MS-CXR,-1,-1
63876442727ddf9f05e58eef,raw gaze data,-1,-1
63876442727ddf9f05e58ef1,HiNER-original,-1,-1
63876442727ddf9f05e58ef3,SoftAttributes,-1,-1
63876442727ddf9f05e58ef5,A collection of LFR benchmark graphs,-1,-1
63876442727ddf9f05e58ef7,COCO-CN,-1,-1
63876442727ddf9f05e58ef9,COUGHVID,-1,-1
63876442727ddf9f05e58efb,Beyond the Imitation Game Benchmark,-1,-1
63876442727ddf9f05e58efd,MATRES,-1,-1
63876442727ddf9f05e58eff,Quality of Movement Assessment for Rehabilitation,-1,-1
63876442727ddf9f05e58f01,Sparse LiDAR KITTI dataset,-1,-1
63876442727ddf9f05e58f03,Panoptic,-1,-1
63876442727ddf9f05e58f05,Multi-View Partial point cloud,-1,-1
63876442727ddf9f05e58f07,Pirá,-1,-1
63876442727ddf9f05e58f09,3D Lane Synthetic Dataset,-1,-1
63876442727ddf9f05e58f0b,DanbooRegion,-1,-1
63876442727ddf9f05e58f0d,MTNT,-1,-1
63876442727ddf9f05e58f0f,"Dataset for: ""It is just a flu: Assessing the Effect of Watch History on YouTube's Pseudoscientific Video Recommendations""",-1,-1
63876442727ddf9f05e58f11,NCT-CRC-HE-100K,-1,-1
63876442727ddf9f05e58f13,Replica,-1,-1
63876442727ddf9f05e58f15,WEB-FORUM-52 gold standard,-1,-1
63876442727ddf9f05e58f17,SWDE,-1,-1
63876442727ddf9f05e58f19,ML guided Logic synthesis,-1,-1
63876442727ddf9f05e58f1b,PROTEINS,-1,-1
63876442727ddf9f05e58f1d,FB1.5M,-1,-1
63876442727ddf9f05e58f1f,ZooScanNet,-1,-1
63876442727ddf9f05e58f21,Criteo live traffic data,-1,-1
63876442727ddf9f05e58f23,ViText2SQL,-1,-1
63876442727ddf9f05e58f25,Pump and dump dataset,-1,-1
63876442727ddf9f05e58f27,CAR,-1,-1
63876442727ddf9f05e58f29,BBBC039,-1,-1
63876442727ddf9f05e58f2b,DDAD,-1,-1
63876442727ddf9f05e58f2d,IndicGLUE,-1,-1
63876442727ddf9f05e58f2f,Multimodal PISA,-1,-1
63876442727ddf9f05e58f31,Tecnocampus Hand Image Database,-1,-1
63876442727ddf9f05e58f33,Correlated and Imbalanced MNIST,-1,-1
63876442727ddf9f05e58f35,COCO Object Detection VIPriors subset,-1,-1
63876442727ddf9f05e58f37,Toloka WaterMeters,-1,-1
63876442727ddf9f05e58f39,CARLANE Benchmark,-1,-1
63876442727ddf9f05e58f3b,Waste Classification data,-1,-1
63876442727ddf9f05e58f3d,Liver Tumor Segmentation Challenge 2017,-1,-1
63876442727ddf9f05e58f3f,Replay-Mobile,-1,-1
63876442727ddf9f05e58f41,SECBENCH,-1,-1
63876442727ddf9f05e58f43,The Laboratory for Web Algorithmics,-1,-1
63876442727ddf9f05e58f45,COCO,-1,-1
63876442727ddf9f05e58f47,HO-3D,-1,-1
63876442727ddf9f05e58f49,IndoNLI,-1,-1
63876442727ddf9f05e58f4b,WikiDes,-1,-1
63876442727ddf9f05e58f4d,ITB,-1,-1
63876442727ddf9f05e58f4f,Indonesian Speech Data,-1,-1
63876442727ddf9f05e58f51,VISION,-1,-1
63876442727ddf9f05e58f53,BuzzFeed-Webis Fake News Corpus 2016,-1,-1
63876442727ddf9f05e58f55,OrdinalDataset,-1,-1
63876442727ddf9f05e58f57,BioRED,-1,-1
63876442727ddf9f05e58f59,STAR: A Benchmark for Situated Reasoning in Real-World Videos,-1,-1
63876442727ddf9f05e58f5b,Reasonable Crowd,-1,-1
63876442727ddf9f05e58f5d,MAVS,-1,-1
63876442727ddf9f05e58f5f,MultiLingual Question Answering,-1,-1
63876442727ddf9f05e58f61,OQMD v1.2,-1,-1
63876442727ddf9f05e58f63,MMAct,-1,-1
63876442727ddf9f05e58f65,SynthCity,-1,-1
63876442727ddf9f05e58f67,STREETS,-1,-1
63876442727ddf9f05e58f69,ORConvQA,-1,-1
63876442727ddf9f05e58f6b,ZESHEL,-1,-1
63876442727ddf9f05e58f6d,OSS for Social Good Project List,-1,-1
63876442727ddf9f05e58f6f,KoDF,-1,-1
63876442727ddf9f05e58f71,CoDEx Medium,-1,-1
63876442727ddf9f05e58f73,StarCraft Multi-Agent Challenge Plus,-1,-1
63876442727ddf9f05e58f75,Interactive Gibson Environment,-1,-1
63876442727ddf9f05e58f77,MultiSubs: A Large-scale Multimodal and Multilingual Dataset,-1,-1
63876442727ddf9f05e58f79,MSP-Podcast,-1,-1
63876442727ddf9f05e58f7b,Multi_Channel_Grid,-1,-1
63876442727ddf9f05e58f7d,CLOze test by TeacHers,-1,-1
63876442727ddf9f05e58f7f,CARD-660,-1,-1
63876442727ddf9f05e58f81,HAKE,-1,-1
63876442727ddf9f05e58f83,FKD,-1,-1
63876442727ddf9f05e58f85,IMDb Movie Reviews,-1,-1
63876442727ddf9f05e58f87,MIMIC PERform Testing Dataset,-1,-1
63876442727ddf9f05e58f89,DailyDialog,-1,-1
63876442727ddf9f05e58f8b,French CASS dataset,-1,-1
63876442727ddf9f05e58f8d,ViViD++,-1,-1
63876442727ddf9f05e58f8f,Evaluating registrations of serial sections with distortions of the ground truths. Supplemental data,-1,-1
63876442727ddf9f05e58f91,SVIRO,-1,-1
63876442727ddf9f05e58f93,100DOH,-1,-1
63876442727ddf9f05e58f95,NaturalProofs,-1,-1
63876442727ddf9f05e58f97,Social-IQ,-1,-1
63876442727ddf9f05e58f99,Botswana,-1,-1
63876442727ddf9f05e58f9b,The 3rd China Physiological Signal Challenge 2020,-1,-1
63876442727ddf9f05e58f9d,RELLIS-3D,-1,-1
63876442727ddf9f05e58f9f,HellaSwag,-1,-1
63876442727ddf9f05e58fa1,Oulu-CASIA,-1,-1
63876442727ddf9f05e58fa3,Eisen Funcat,-1,-1
63876442727ddf9f05e58fa5,CoVoST,-1,-1
63876442727ddf9f05e58fa7,Middlebury 2014,-1,-1
63876442727ddf9f05e58fa9,MPII Cooking 2 Dataset,-1,-1
63876442727ddf9f05e58fab,FoolMeTwice,-1,-1
63876442727ddf9f05e58fad,PDE dataset,-1,-1
63876442727ddf9f05e58faf,A-OKVQA,-1,-1
63876442727ddf9f05e58fb1,Depth in the Wild,-1,-1
63876442727ddf9f05e58fb3,ECG in High Intensity Exercise Dataset,-1,-1
63876442727ddf9f05e58fb5,FSC147,-1,-1
63876442727ddf9f05e58fb7,N-Digit MNIST,-1,-1
63876442727ddf9f05e58fb9,Extended Labeled Faces in-the-Wild,-1,-1
63876442727ddf9f05e58fbb,WebChild,-1,-1
63876442727ddf9f05e58fbd,Nations,-1,-1
63876442727ddf9f05e58fbf,Cam2BEV,-1,-1
63876442727ddf9f05e58fc1,HANNA,-1,-1
63876442727ddf9f05e58fc3,EVIL,-1,-1
63876442727ddf9f05e58fc5,OpenEA Benchmark,-1,-1
63876442727ddf9f05e58fc7,A2Dre,-1,-1
63876442727ddf9f05e58fc9,DAGW,-1,-1
63876442727ddf9f05e58fcb,IQR,-1,-1
63876442727ddf9f05e58fcd,Set5,-1,-1
63876442727ddf9f05e58fcf,ARCA23K,-1,-1
63876442727ddf9f05e58fd1,KACC,-1,-1
63876443727ddf9f05e58fd3,UCSD Ped2,-1,-1
63876443727ddf9f05e58fd5,NEMO Hebrew NER and Morphology Corpus,-1,-1
63876443727ddf9f05e58fd7,Breast Cancer Immunohistochemical Image Generation,-1,-1
63876443727ddf9f05e58fd9,DocBank-TB,-1,-1
63876443727ddf9f05e58fdb,Derisi Funcat,-1,-1
63876443727ddf9f05e58fdd,Mall,-1,-1
63876443727ddf9f05e58fdf,Toyota Smarthome Trimmed,-1,-1
63876443727ddf9f05e58fe1,Movie Fill-in-the-Blank,-1,-1
63876443727ddf9f05e58fe3,Multilingual and Code-mixed Visual Question Answering,-1,-1
63876443727ddf9f05e58fe5,Wiki-CS,-1,-1
63876443727ddf9f05e58fe7,Cross-Linguistic Polysemies,-1,-1
63876443727ddf9f05e58fe9,P3,-1,-1
63876443727ddf9f05e58feb,MUNO21,-1,-1
63876443727ddf9f05e58fed,Multi-Spectral Leaf Segmentation For Crop/Weed Identification,-1,-1
63876443727ddf9f05e58fef,WMT 2014 Medical,-1,-1
63876443727ddf9f05e58ff1,DIR-LAB COPDgene,-1,-1
63876443727ddf9f05e58ff3,UniMiB SHAR,-1,-1
63876443727ddf9f05e58ff5,AnimalWeb,-1,-1
63876443727ddf9f05e58ff7,IowaRain,-1,-1
63876443727ddf9f05e58ff9,Multimodal Spontaneous Expression-Heart Rate dataset,-1,-1
63876443727ddf9f05e58ffb,Flickr Cropping Dataset,-1,-1
63876443727ddf9f05e58ffd,PEC,-1,-1
63876443727ddf9f05e58fff,The 'Call me sexist but' Dataset (CMSB),-1,-1
63876443727ddf9f05e59001,CIFAR-10,-1,-1
63876443727ddf9f05e59003,Monocular 3D Lane Detection Dataset,-1,-1
63876443727ddf9f05e59005,Microsoft Learning to Rank Datasets-30k,-1,-1
63876443727ddf9f05e59007,SLURP,-1,-1
63876443727ddf9f05e59009,BH-rPPG,-1,-1
63876443727ddf9f05e5900b,esXNLI,-1,-1
63876443727ddf9f05e5900d,Abt-Buy,-1,-1
63876443727ddf9f05e5900f,"9,497 Images - OCR Data of 10 Types of Forms",-1,-1
63876443727ddf9f05e59011,Many Faces of Anger,-1,-1
63876443727ddf9f05e59013,CAMUS,-1,-1
63876443727ddf9f05e59015,DCF Valuation template,-1,-1
63876443727ddf9f05e59017,Open-Domain Spoken Question Answering,-1,-1
63876443727ddf9f05e59019,Liverpool 360 degree Street View,-1,-1
63876443727ddf9f05e5901b,COCO-Stuff,-1,-1
63876443727ddf9f05e5901d,A*3D,-1,-1
63876443727ddf9f05e5901f,arXiv Astro-Ph,-1,-1
63876443727ddf9f05e59021,MP-3DHP: Multi-Person 3D Human Pose Dataset,-1,-1
63876443727ddf9f05e59023,Moral Foundations Reddit Corpus,-1,-1
63876443727ddf9f05e59025,Trailers12k,-1,-1
63876443727ddf9f05e59027,WEB-FORUM-52,-1,-1
63876443727ddf9f05e59029,Rendered WB dataset,-1,-1
63876443727ddf9f05e5902b,Multiple Light Source,-1,-1
63876443727ddf9f05e5902d,Tunisian Sentiment Analysis Corpus,-1,-1
63876443727ddf9f05e5902f,Emomusic,-1,-1
63876443727ddf9f05e59031,Pre-Contest Workshop Slidedeck,-1,-1
63876443727ddf9f05e59033,DRealSR,-1,-1
63876443727ddf9f05e59035,CUHK01,-1,-1
63876443727ddf9f05e59037,ModelNet40-C,-1,-1
63876443727ddf9f05e59039,PEMS-BAY Point Missing,-1,-1
63876443727ddf9f05e5903b,Frames Dataset,-1,-1
63876443727ddf9f05e5903d,MICCAI'2015 Gland Segmentation Challenge Contest Dataset,-1,-1
63876443727ddf9f05e5903f,Wiki-Reliability,-1,-1
63876443727ddf9f05e59041,MetaGraspNet difficulty 4 - hard 2,-1,-1
63876443727ddf9f05e59043,Visual Wake Words,-1,-1
63876443727ddf9f05e59045,Kvasir-SEG,-1,-1
63876443727ddf9f05e59047,The Samsung Open MOS Dataset for the Evaluation of Neural Text-to-Speech Synthesis,-1,-1
63876443727ddf9f05e59049,Visual Dialog,-1,-1
63876443727ddf9f05e5904b,COVID-19 Image Data Collection,-1,-1
63876443727ddf9f05e5904d,WiLI-2018,-1,-1
63876443727ddf9f05e5904f,Topo-boundary,-1,-1
63876443727ddf9f05e59051,speechocean762,-1,-1
63876443727ddf9f05e59053,WHO-COVID19 Dataset,-1,-1
63876443727ddf9f05e59055,Rendered SST2,-1,-1
63876443727ddf9f05e59057,French Question Answering Dataset,-1,-1
63876443727ddf9f05e59059,PCD,-1,-1
63876443727ddf9f05e5905b,PhC-U373,-1,-1
63876443727ddf9f05e5905d,CBC,-1,-1
63876443727ddf9f05e5905f,xP3,-1,-1
63876443727ddf9f05e59061,Uzbek Speech Corpus,-1,-1
63876443727ddf9f05e59063,GeoQA,-1,-1
63876443727ddf9f05e59065,MLFP,-1,-1
63876443727ddf9f05e59067,CIC,-1,-1
63876443727ddf9f05e59069,50 Salads,-1,-1
63876443727ddf9f05e5906b,MineRL,-1,-1
63876443727ddf9f05e5906d,Exclusively Dark Image Dataset,-1,-1
63876443727ddf9f05e5906f,NASA Worldview,-1,-1
63876443727ddf9f05e59071,ROSE,-1,-1
63876443727ddf9f05e59073,Wind Tunnel and Flight Test Experiments,-1,-1
63876443727ddf9f05e59075,UG^2,-1,-1
63876443727ddf9f05e59077,ClovaCall,-1,-1
63876443727ddf9f05e59079,HErlev,-1,-1
63876443727ddf9f05e5907b,Jericho Environment Commonsense Comprehension,-1,-1
63876443727ddf9f05e5907d,MASSIVE,-1,-1
63876443727ddf9f05e5907f,Dialogue State Tracking Challenge,-1,-1
63876443727ddf9f05e59081,CLOUD Dataset,-1,-1
63876443727ddf9f05e59083,Financial Language Understanding Evaluation,-1,-1
63876443727ddf9f05e59085,Street Scene,-1,-1
63876443727ddf9f05e59087,Blocksworld Image Reasoning Dataset,-1,-1
63876443727ddf9f05e59089,Danish Airs and Grounds,-1,-1
63876443727ddf9f05e5908b,Composed Quora,-1,-1
63876443727ddf9f05e5908d,Deepfake videos generated from different models,-1,-1
63876443727ddf9f05e5908f,"Twitter dataset of flood-related images for September 2021, Thailand and June/July 2021, Nepal floods",-1,-1
63876443727ddf9f05e59091,DFDC,-1,-1
63876443727ddf9f05e59093,TriggerCit 2021 Thailand / Nepal floods,-1,-1
63876443727ddf9f05e59095,Capture-24,-1,-1
63876443727ddf9f05e59097,LAAS Parkour dataset,-1,-1
63876443727ddf9f05e59099,V4V,-1,-1
63876443727ddf9f05e5909b,Snips-SmartLights,-1,-1
63876443727ddf9f05e5909d,SKAB,-1,-1
63876443727ddf9f05e5909f,Diagnostic Evaluation of Video Inpainting on Landscapes,-1,-1
63876443727ddf9f05e590a1,RENOIR,-1,-1
63876443727ddf9f05e590a3,Multimodal Mobile Biometric Database,-1,-1
63876443727ddf9f05e590a5,MOTChallenge,-1,-1
63876443727ddf9f05e590a7,Dialog System Technology Challenges 8 Track 2,-1,-1
63876443727ddf9f05e590a9,PPG and Blood Pressure from a Hypertensive Population,-1,-1
63876443727ddf9f05e590ab,Video2GIF,-1,-1
63876443727ddf9f05e590ad,PhyAAt,-1,-1
63876443727ddf9f05e590af,DIBCO 2017,-1,-1
63876443727ddf9f05e590b1,Inclusive Fashion AI,-1,-1
63876443727ddf9f05e590b3,VDQG,-1,-1
63876443727ddf9f05e590b5,endless forams,-1,-1
63876443727ddf9f05e590b7,INTERSPEECH 2021 Acoustic Echo Cancellation Challenge,-1,-1
63876443727ddf9f05e590b9,TBCOV,-1,-1
63876443727ddf9f05e590bb,CMRC 2018,-1,-1
63876443727ddf9f05e590bd,LITIS Rouen,-1,-1
63876443727ddf9f05e590bf,EGAD,-1,-1
63876443727ddf9f05e590c1,American English Speech Data,-1,-1
63876443727ddf9f05e590c3,Refer360°,-1,-1
63876443727ddf9f05e590c5,Cornell Movie-Quotes Corpus,-1,-1
63876443727ddf9f05e590c7,Streetscore,-1,-1
63876443727ddf9f05e590c9,COVID-19-CT-CXR,-1,-1
63876443727ddf9f05e590cb,DUC 2006,-1,-1
63876443727ddf9f05e590ce,Small-Molecule/Protein Interaction Chemical Energies,-1,-1
63876443727ddf9f05e590d0,Multi-Language Vocabulary Evaluation,-1,-1
63876443727ddf9f05e590d2,ATRW,-1,-1
63876443727ddf9f05e590d4,Automating Dynamic Consent,-1,-1
63876443727ddf9f05e590d7,H3D,-1,-1
63876443727ddf9f05e590d9,ArtImage,-1,-1
63876443727ddf9f05e590db,ChangeSim,-1,-1
63876443727ddf9f05e590dd,SICAPv2,-1,-1
63876443727ddf9f05e590df,WSJ0-2mix,-1,-1
63876443727ddf9f05e590e1,MultiviewX,-1,-1
63876443727ddf9f05e590e3,ORVS,-1,-1
63876443727ddf9f05e590e5,OOVD,-1,-1
63876443727ddf9f05e590e7,Opinosis,-1,-1
63876443727ddf9f05e590e9,CER Smart Metering Project - Electricity Customer Behaviour Trial,-1,-1
63876443727ddf9f05e590eb,SMC Text Corpus,-1,-1
63876443727ddf9f05e590ed,TV show Retrieval,-1,-1
63876443727ddf9f05e590ef,OxUva,-1,-1
63876443727ddf9f05e590f1,K-pop Idol Dataset - Female,-1,-1
63876443727ddf9f05e590f3,Anime Face Dataset by Character Name,-1,-1
63876443727ddf9f05e590f5,Night Object Detection,-1,-1
63876443727ddf9f05e590f7,PS-Battles,-1,-1
63876443727ddf9f05e590f9,"23,110 People Multi-race and Multi-pose Face Images Data",-1,-1
63876443727ddf9f05e590fb,Probably Asked Questions,-1,-1
63876443727ddf9f05e590fd,Tobacco-3482,-1,-1
63876443727ddf9f05e590ff,MTASS,-1,-1
63876443727ddf9f05e59101,ES-ImageNet,-1,-1
63876443727ddf9f05e59103,SVAMP,-1,-1
63876443727ddf9f05e59105,H2O  (2 Hands and Objects),-1,-1
63876443727ddf9f05e59107,Enoch Oluwumi,-1,-1
63876443727ddf9f05e59109,Ciona17,-1,-1
63876443727ddf9f05e5910b,Cloud VR gaming network traffic data,-1,-1
63876443727ddf9f05e5910d,Interactive Question Answering Dataset,-1,-1
63876443727ddf9f05e5910f,HR-GLDD: A globally distributed high resolution landslide dataset,-1,-1
63876443727ddf9f05e59111,Sports-1M,-1,-1
63876443727ddf9f05e59113,Human Wrist Image Dataset | Human Body Parts,-1,-1
63876443727ddf9f05e59115,ecoset,-1,-1
63876443727ddf9f05e59117,Thumb Index 1000 Hand & Fingertip Detection Dataset,-1,-1
63876443727ddf9f05e59119,SpaceNet MVOI,-1,-1
63876443727ddf9f05e5911b,"GermEval 2021 - Toxic, Engaging, & Fact-Claiming Comments test set",-1,-1
63876443727ddf9f05e5911d,Open Set Logo Detection Dataset,-1,-1
63876443727ddf9f05e5911f,RTC,-1,-1
63876443727ddf9f05e59121,The Kvasir Dataset,-1,-1
63876443727ddf9f05e59123,WHAM!,-1,-1
63876443727ddf9f05e59125,Spatial Commonsense Graph Dataset,-1,-1
63876443727ddf9f05e59127,Qulac,-1,-1
63876443727ddf9f05e59129,Dark Machines Anomaly Score,-1,-1
63876443727ddf9f05e5912b,DpgMedia2019,-1,-1
63876443727ddf9f05e5912d,Survey Variable Identification,-1,-1
63876443727ddf9f05e5912f,Localized Audio Visual DeepFake Dataset,-1,-1
63876443727ddf9f05e59131,"4,995 Vietnamese OCR Images Data - Images with Annotation and Transcription",-1,-1
63876443727ddf9f05e59134,HDR+ Burst Photography Dataset,-1,-1
63876443727ddf9f05e59136,Universal Dependencies,-1,-1
63876443727ddf9f05e59138,CASIA-WebFace+masks,-1,-1
63876443727ddf9f05e5913a,HRF,-1,-1
63876443727ddf9f05e5913c,Violent-Flows,-1,-1
63876443727ddf9f05e5913e,AmsterTime,-1,-1
63876443727ddf9f05e59140,French Language Understanding Evaluation,-1,-1
63876443727ddf9f05e59142,Fine-Grained Entity Recognition,-1,-1
63876443727ddf9f05e59144,QMNIST,-1,-1
63876443727ddf9f05e59146,BiToD,-1,-1
63876443727ddf9f05e59148,X4K1000FPS,-1,-1
63876443727ddf9f05e5914a,HD1k,-1,-1
63876443727ddf9f05e5914c,WikiAnn,-1,-1
63876443727ddf9f05e5914e,HelloWorld,-1,-1
63876443727ddf9f05e59150,Task-driven Embodied Agents that Chat,-1,-1
63876443727ddf9f05e59152,pic2kcal,-1,-1
63876443727ddf9f05e59154,Citation Network Dataset,-1,-1
63876443727ddf9f05e59156,MultiOpEd,-1,-1
63876443727ddf9f05e59158,Synthetic and Real Apache Log Records,-1,-1
63876443727ddf9f05e5915a,ToN_IoT,-1,-1
63876443727ddf9f05e5915c,IPOD,-1,-1
63876443727ddf9f05e5915e,AQUA,-1,-1
63876443727ddf9f05e59160,The Deformable Image Registration Laboratory,-1,-1
63876443727ddf9f05e59162,Self-reported Mental Health Diagnoses,-1,-1
63876443727ddf9f05e59164,Varied Emotion in Syntactically Uniform Speech,-1,-1
63876443727ddf9f05e59166,JTA,-1,-1
63876443727ddf9f05e59168,Ruralscapes,-1,-1
63876443727ddf9f05e5916a,Dario Pilori,-1,-1
63876443727ddf9f05e5916c,ASAYAR,-1,-1
63876443727ddf9f05e5916e,iNat2021,-1,-1
63876443727ddf9f05e59170,GGPONC,-1,-1
63876443727ddf9f05e59172,2021 Hotel-ID,-1,-1
63876443727ddf9f05e59174,Hate Speech and Offensive Language,-1,-1
63876443727ddf9f05e59176,DeliData,-1,-1
63876443727ddf9f05e59178,Plant Centroids,-1,-1
63876443727ddf9f05e5917a,VLOG Dataset,-1,-1
63876443727ddf9f05e5917c,531 Hours – In-Car Noise Data by Microphone and Mobile Phone,-1,-1
63876443727ddf9f05e5917e,ArtFID Dataset,-1,-1
63876443727ddf9f05e59180,BPCIS,-1,-1
63876443727ddf9f05e59182,Swarm Heuristics based Adaptive and Penalized Estimation of Splines,-1,-1
63876443727ddf9f05e59184,ASLLVD,-1,-1
63876443727ddf9f05e59187,Lens Flare Dataset,-1,-1
63876443727ddf9f05e59189,Sustainable Venture Capital Survey 2022,-1,-1
63876443727ddf9f05e5918b,MPI3D Disentanglement,-1,-1
63876443727ddf9f05e5918d,xBD,-1,-1
63876443727ddf9f05e5918f,DSTC7 Task 2,-1,-1
63876443727ddf9f05e59191,Dataset of Industrial Metal Objects,-1,-1
63876443727ddf9f05e59193,Cumulo,-1,-1
63876443727ddf9f05e59195,Reddit TIFU,-1,-1
63876443727ddf9f05e59197,2012 i2b2 Clinical Temporal Relations,-1,-1
63876443727ddf9f05e59199,EIGD-H,-1,-1
63876443727ddf9f05e5919b,ICT-3DHP,-1,-1
63876443727ddf9f05e5919d,Few-Shot Object Detection Dataset,-1,-1
63876443727ddf9f05e5919f,SpaRTUN,-1,-1
63876443727ddf9f05e591a1,Something-Something V2,-1,-1
63876443727ddf9f05e591a3,Something-Something V1,-1,-1
63876443727ddf9f05e591a5,Flowchart Grounded Dialogs Dataset,-1,-1
63876443727ddf9f05e591a7,University of Bucharest Abnormal Videos,-1,-1
63876443727ddf9f05e591a9,AVD,-1,-1
63876443727ddf9f05e591ab,Multi-species fruit flower detection datasets,-1,-1
63876443727ddf9f05e591ad,IMDB-BINARY,-1,-1
63876443727ddf9f05e591af,Video Person-Clustering,-1,-1
63876443727ddf9f05e591b1,CUHK Person Re-identification Dataset,-1,-1
63876443727ddf9f05e591b3,HyperSpectral Salient Object Detection Dataset,-1,-1
63876443727ddf9f05e591b5,VehicleID,-1,-1
63876443727ddf9f05e591b7,ISAdetect binary file and object code dataset,-1,-1
63876443727ddf9f05e591b9,SemEval-2018 Task 9: Hypernym Discovery,-1,-1
63876443727ddf9f05e591bb,Human POSEitioning System Dataset,-1,-1
63876443727ddf9f05e591bd,MIMIC-IV-ED,-1,-1
63876443727ddf9f05e591bf,Microblog Opinion Summarisation,-1,-1
63876443727ddf9f05e591c1,Computer Vision Values Dataset,-1,-1
63876443727ddf9f05e591c3,ToxiGen,-1,-1
63876443727ddf9f05e591c5,rc_49,-1,-1
63876443727ddf9f05e591c7,CRL-Person,-1,-1
63876443727ddf9f05e591ca,Sports Shape and Pose 3D,-1,-1
63876443727ddf9f05e591cc,SC_burst,-1,-1
63876443727ddf9f05e591ce,More Inclusive Annotations for People,-1,-1
63876443727ddf9f05e591d0,ITG,-1,-1
63876443727ddf9f05e591d2,InfographicVQA,-1,-1
63876443727ddf9f05e591d4,AwA Pose,-1,-1
63876443727ddf9f05e591d6,Captured Raw Video Denoising,-1,-1
63876443727ddf9f05e591d8,Oxford Multimotion Dataset,-1,-1
63876443727ddf9f05e591da,"Supporting data for ""Multi-Stage Malaria Parasites Recognition by Deep Learning""",-1,-1
63876443727ddf9f05e591dc,Congressional Voting Records Data Set,-1,-1
63876443727ddf9f05e591df,CLEVR,-1,-1
63876443727ddf9f05e591e1,Synthetic Interventions on Scenes for Robustness Evaluation,-1,-1
63876443727ddf9f05e591e3,GDSCv2,-1,-1
63876443727ddf9f05e591e5,VegFru,-1,-1
63876443727ddf9f05e591e7,JRDB-Act,-1,-1
63876443727ddf9f05e591e9,SciDuet,-1,-1
63876443727ddf9f05e591eb,DX7 Timbre Dataset,-1,-1
63876443727ddf9f05e591ed,FLAT,-1,-1
63876443727ddf9f05e591ef,Japanese Speech Data by Mobile Phone,-1,-1
63876443727ddf9f05e591f1,PlantDoc,-1,-1
63876443727ddf9f05e591f3,How2R,-1,-1
63876443727ddf9f05e591f5,FarsTail,-1,-1
63876443727ddf9f05e591f7,TASTEset,-1,-1
63876443727ddf9f05e591f9,A Datacube for the analysis of wildfires in Greece,-1,-1
63876443727ddf9f05e591fb,JSESM Publications,-1,-1
63876443727ddf9f05e591fd,SciERC,-1,-1
63876443727ddf9f05e591ff,COOLL,-1,-1
63876443727ddf9f05e59201,CoronaVis,-1,-1
63876443727ddf9f05e59203,TEP,-1,-1
63876443727ddf9f05e59205,Images from camera traps in the Jura and Ain counties (France),-1,-1
63876443727ddf9f05e59207,Wikipedia Biography Dataset,-1,-1
63876443727ddf9f05e59209,eICU Collaborative Research Database,-1,-1
63876443727ddf9f05e5920b,WebQA,-1,-1
63876443727ddf9f05e5920d,Canadian Speaking English Speech Data,-1,-1
63876443727ddf9f05e5920f,IS-A,-1,-1
63876443727ddf9f05e59211,TimeBankPT,-1,-1
63876443727ddf9f05e59213,Romanian Named Entity Corpus,-1,-1
63876443727ddf9f05e59215,MCVQA,-1,-1
63876443727ddf9f05e59217,WebQuestionsSP,-1,-1
63876443727ddf9f05e59219,MetaGraspNet 1,-1,-1
63876443727ddf9f05e5921b,TCP-CI,-1,-1
63876443727ddf9f05e5921d,FeedbackQA,-1,-1
63876443727ddf9f05e5921f,CliCR,-1,-1
63876443727ddf9f05e59221,PhoNER COVID19,-1,-1
63876443727ddf9f05e59223,HateScore,-1,-1
63876443727ddf9f05e59225,Kuzushiji-MNIST,-1,-1
63876443727ddf9f05e59227,Professional go annotation dataset,-1,-1
63876443727ddf9f05e59229,Konstanz Image Quality 10k Database,-1,-1
63876443727ddf9f05e5922b,MSLR WEB30K,-1,-1
63876443727ddf9f05e5922d,BraTS 2018,-1,-1
63876443727ddf9f05e5922f,METU-VIREF Dataset,-1,-1
63876443727ddf9f05e59231,SEN12MS-CR-TS,-1,-1
63876443727ddf9f05e59233,DailyDialog++,-1,-1
63876443727ddf9f05e59235,AI2D-RST,-1,-1
63876443727ddf9f05e59237,Intel Lab Data,-1,-1
63876443727ddf9f05e59239,ChAII - Hindi and Tamil Question Answering,-1,-1
63876443727ddf9f05e5923b,3DNet,-1,-1
63876443727ddf9f05e5923d,OpenEDS2020,-1,-1
63876443727ddf9f05e5923f,AIDS,-1,-1
63876443727ddf9f05e59241,Yelp-Fraud,-1,-1
63876443727ddf9f05e59243,Epinion,-1,-1
63876443727ddf9f05e59245,SEL,-1,-1
63876443727ddf9f05e59247,RuFa,-1,-1
63876443727ddf9f05e59249,York Urban Line Segment Database,-1,-1
63876443727ddf9f05e5924b,TREC-10,-1,-1
63876443727ddf9f05e5924d,SemClinBr,-1,-1
63876443727ddf9f05e5924f,Nakdimon-train,-1,-1
63876443727ddf9f05e59251,LAION COCO,-1,-1
63876443727ddf9f05e59253,LIVE-FB LSVQ,-1,-1
63876443727ddf9f05e59255,aPY,-1,-1
63876443727ddf9f05e59257,Invisible Mobile Keyboard Dataset,-1,-1
63876443727ddf9f05e59259,ToM QA,-1,-1
63876443727ddf9f05e5925b,Adobe Visual Font Recognition real-world images dataset,-1,-1
63876443727ddf9f05e5925d,ACM,-1,-1
63876443727ddf9f05e59260,ChEMBL v.27,-1,-1
63876443727ddf9f05e59262,Visual Object Tracking Challenge 2015,-1,-1
63876443727ddf9f05e59264,UMAD,-1,-1
63876443727ddf9f05e59266,MIT-Princeton Amazon Picking Challenge 2016 Shelf&Tote Benchmark Dataset,-1,-1
63876443727ddf9f05e59268,Translated TACRED,-1,-1
63876443727ddf9f05e5926a,Distinct Describable Moments,-1,-1
63876443727ddf9f05e5926c,EmotionLines,-1,-1
63876443727ddf9f05e5926e,URMP,-1,-1
63876443727ddf9f05e59270,Procedurally Generated Matrices (PGM),-1,-1
63876443727ddf9f05e59272,SubjQA,-1,-1
63876443727ddf9f05e59274,The Open Quantum Materials Database,-1,-1
63876443727ddf9f05e59276,Gallbladder Cancer Ultrasound Dataset,-1,-1
63876443727ddf9f05e59278,Pan-STARRS,-1,-1
63876443727ddf9f05e5927a,SpeakingFaces,-1,-1
63876443727ddf9f05e5927c,20 Hours - American English Speech Synthesis Corpus-Male,-1,-1
63876443727ddf9f05e5927e,Nighttime Driving,-1,-1
63876443727ddf9f05e59280,300 Hours - Tibetan Colloquial Video Speech Data,-1,-1
63876443727ddf9f05e59282,PBC,-1,-1
63876443727ddf9f05e59284,JerichoWorld,-1,-1
63876443727ddf9f05e59286,DeepFashion,-1,-1
63876443727ddf9f05e59288,German affixoid dataset,-1,-1
63876443727ddf9f05e5928a,ComPhy,-1,-1
63876443727ddf9f05e5928c,TVQA+,-1,-1
63876443727ddf9f05e5928e,Prophesee GEN1 Automotive Detection Dataset,-1,-1
63876443727ddf9f05e59290,Crowd in a rally | Crowd Counting | Crowd Human,-1,-1
63876443727ddf9f05e59292,TCIA Test & Validation Radiotherapy CT Planning Scan,-1,-1
63876443727ddf9f05e59294,RWTH-PHOENIX-Weather 2014,-1,-1
63876443727ddf9f05e59296,CPCXR,-1,-1
63876443727ddf9f05e59298,Totally-Looks-Like,-1,-1
63876443727ddf9f05e5929a,Biomedical Language Understanding and Reasoning Benchmark,-1,-1
63876443727ddf9f05e5929c,"Data for paper ""Zone extrapolations in parametric timed automata""",-1,-1
63876443727ddf9f05e5929e,Aerial Coastline Imagery Dataset,-1,-1
63876443727ddf9f05e592a0,Extended UCF Crime,-1,-1
63876443727ddf9f05e592a2,Family101,-1,-1
63876443727ddf9f05e592a4,ModelNet-C,-1,-1
63876443727ddf9f05e592a6,VoxLingua107,-1,-1
63876443727ddf9f05e592a8,InstaCities1M,-1,-1
63876443727ddf9f05e592aa,LIVE Video Quality Challenge (VQC) Database,-1,-1
63876443727ddf9f05e592ac,Konzilsprotokolle_C,-1,-1
63876443727ddf9f05e592ae,ALGAD,-1,-1
63876443727ddf9f05e592b0,SG-NLG,-1,-1
63876443727ddf9f05e592b2,SHAD3S,-1,-1
63876443727ddf9f05e592b4,"1,420 Hours- Mandarin Spontaneous Speech Data by Mobile Phone",-1,-1
63876443727ddf9f05e592b6,"Chinese Mandarin Synthesis Corpus-Female, Customer Service",-1,-1
63876443727ddf9f05e592b8,ELEVATER,-1,-1
63876443727ddf9f05e592ba,Breaking Bad,-1,-1
63876443727ddf9f05e592bc,PRImA,-1,-1
63876443727ddf9f05e592be,FewGlue,-1,-1
63876443727ddf9f05e592c0,adobe panorama dataset,-1,-1
63876443727ddf9f05e592c2,ActioNet,-1,-1
63876443727ddf9f05e592c4,Making the Most of Text Semantics to Improve Biomedical Vision-Language Processing,-1,-1
63876443727ddf9f05e592c6,GID,-1,-1
63876443727ddf9f05e592c8,Kinteract,-1,-1
63876443727ddf9f05e592ca,xView3-SAR,-1,-1
63876443727ddf9f05e592cc,How2QA,-1,-1
63876443727ddf9f05e592ce,Multi-aspect Integrated Migration Indicators dataset,-1,-1
63876443727ddf9f05e592d0,Temperature Field Reconstruction Dataset,-1,-1
63876443727ddf9f05e592d2,OASIS-1,-1,-1
63876443727ddf9f05e592d4,Articulation GAN: Unsupervised modeling of articulatory learning,-1,-1
63876443727ddf9f05e592d6,ASSET,-1,-1
63876443727ddf9f05e592d8,The MuDoCo dataset with Query Rewrite Annotations,-1,-1
63876443727ddf9f05e592da,IAM Dataset,-1,-1
63876443727ddf9f05e592dc,MSU HDR Video Reconstruction Benchmark,-1,-1
63876443727ddf9f05e592de,MSMT17-C,-1,-1
63876443727ddf9f05e592e0,Datasets for 3D shape reconstruction from 2D microscopy images,-1,-1
63876443727ddf9f05e592e2,TVSum,-1,-1
63876443727ddf9f05e592e4,Hephaestus,-1,-1
63876443727ddf9f05e592e6,NIST Special Dataset 19,-1,-1
63876443727ddf9f05e592e8,SBWCE,-1,-1
63876443727ddf9f05e592ea,MusicVideos,-1,-1
63876443727ddf9f05e592ec,Biomedical Semantic Indexing and Question Answering,-1,-1
63876443727ddf9f05e592ee,A Drone Dataset at Signalized Intersection in China,-1,-1
63876443727ddf9f05e592f0,LIVE YouTube High Frame Rate,-1,-1
63876443727ddf9f05e592f2,PLOD-unfiltered,-1,-1
63876443727ddf9f05e592f4,XL-Sum,-1,-1
63876443727ddf9f05e592f6,Udacity,-1,-1
63876443727ddf9f05e592f8,Cholecystectomy Action Triplet,-1,-1
63876443727ddf9f05e592fa,Science Question Answering,-1,-1
63876443727ddf9f05e592fc,WMT 2015 News Translation Task,-1,-1
63876443727ddf9f05e592fe,VIL-100,-1,-1
63876443727ddf9f05e59300,BCI Competition Datasets,-1,-1
63876443727ddf9f05e59302,GigaSpeech,-1,-1
63876443727ddf9f05e59304,Physiology of Auditory Attention,-1,-1
63876443727ddf9f05e59306,Automated Student Assessment Prize,-1,-1
63876443727ddf9f05e59308,GOF,-1,-1
63876443727ddf9f05e5930a,HAM,-1,-1
63876443727ddf9f05e5930c,T2 Guiding,-1,-1
63876443727ddf9f05e5930e,PFN Visuo-Tactile Dataset,-1,-1
63876443727ddf9f05e59310,FSVQA,-1,-1
63876443727ddf9f05e59312,HiRID,-1,-1
63876443727ddf9f05e59314,UT-Interaction,-1,-1
63876443727ddf9f05e59316,MultiUN,-1,-1
63876443727ddf9f05e59318,PanLex-BLI,-1,-1
63876443727ddf9f05e5931a,FCGEC,-1,-1
63876443727ddf9f05e5931c,Dutch Book Reviews Dataset,-1,-1
63876444727ddf9f05e5931e,USGS Landsat 8 Collection 1 Tier 1 and Real-Time data Raw Scenes [deprecated],-1,-1
63876444727ddf9f05e59320,Incremental Dialog Dataset,-1,-1
63876444727ddf9f05e59322,Switchboard-1 Corpus,-1,-1
63876444727ddf9f05e59324,QuaRel,-1,-1
63876444727ddf9f05e59326,PubMed Cognitive Control Abstracts,-1,-1
63876444727ddf9f05e59328,CoS-E,-1,-1
63876444727ddf9f05e5932a,NELA-GT-2019,-1,-1
63876444727ddf9f05e5932c,iSarcasmEval,-1,-1
63876444727ddf9f05e5932e,Win-Fail Action Understanding,-1,-1
63876444727ddf9f05e59330,Literal Motion in Text Dataset,-1,-1
63876444727ddf9f05e59332,ToyADMOS2,-1,-1
63876444727ddf9f05e59334,ChestX-ray14,-1,-1
63876444727ddf9f05e59336,ViPhy,-1,-1
63876444727ddf9f05e59338,SV-Ident,-1,-1
63876444727ddf9f05e5933a,FFT-75,-1,-1
63876444727ddf9f05e5933c,The Little Prince,-1,-1
63876444727ddf9f05e5933e,QAConv,-1,-1
63876444727ddf9f05e59340,MUSDB18-HQ,-1,-1
63876444727ddf9f05e59342,VideoCC3M,-1,-1
63876444727ddf9f05e59344,SCIAN,-1,-1
63876444727ddf9f05e59346,Dataset of Multimodal Semantic Egocentric Video,-1,-1
63876444727ddf9f05e59348,Cholec80,-1,-1
63876444727ddf9f05e5934a,MQ2007,-1,-1
63876444727ddf9f05e5934c,Spanish Speech Data by Mobile Phone,-1,-1
63876444727ddf9f05e5934e,IKEA ASM,-1,-1
63876444727ddf9f05e59350,Line Coverage Dataset,-1,-1
63876444727ddf9f05e59352,OmniArt,-1,-1
63876444727ddf9f05e59354,iKala,-1,-1
63876444727ddf9f05e59356,SOREL-20M,-1,-1
63876444727ddf9f05e59358,Atari 100k,-1,-1
63876444727ddf9f05e5935a,Medical Question Pairs,-1,-1
63876444727ddf9f05e5935c,AIDS Antiviral Screen,-1,-1
63876444727ddf9f05e5935e,News-Tweet Paired Dataset,-1,-1
63876444727ddf9f05e59360,KuaiRec,-1,-1
63876444727ddf9f05e59362,PoKi,-1,-1
63876444727ddf9f05e59364,Tox21 Machine Learning Data Set,-1,-1
63876444727ddf9f05e59366,RLU,-1,-1
63876444727ddf9f05e59368,COVIDEmo,-1,-1
63876444727ddf9f05e5936a,C&Z,-1,-1
63876444727ddf9f05e5936c,Facebook Low Resource MT Benchmark,-1,-1
63876444727ddf9f05e5936e,SI-Score,-1,-1
63876444727ddf9f05e59370,CIFAR-100,-1,-1
63876444727ddf9f05e59372,"4,134 People – Infrared Face Recognition Data",-1,-1
63876444727ddf9f05e59374,SNLI-VE,-1,-1
63876444727ddf9f05e59376,ESD,-1,-1
63876444727ddf9f05e59378,Extreme Countix-AV,-1,-1
63876444727ddf9f05e5937a,Task Directed Image Understanding Challenge,-1,-1
63876444727ddf9f05e5937c,IWSLT2015,-1,-1
63876444727ddf9f05e5937e,762 Hours - Non-Hispanic Spanish Speech Data by Mobile Phone,-1,-1
63876444727ddf9f05e59380,Indian Number Plates Dataset | Vehicle Number Plates | English OCR Detection,-1,-1
63876444727ddf9f05e59382,R2R,-1,-1
63876444727ddf9f05e59384,Egocentric Dataset of the University of Barcelona – Segmentation,-1,-1
63876444727ddf9f05e59386,Erhu Playing Technique Dataset,-1,-1
63876444727ddf9f05e59388,GRB,-1,-1
63876444727ddf9f05e5938a,Indian Number Plates Dataset,-1,-1
63876444727ddf9f05e5938c,Quora Question Pairs,-1,-1
63876444727ddf9f05e5938e,"1,998 People - Lip Language Video Data",-1,-1
63876444727ddf9f05e59390,HiXray,-1,-1
63876444727ddf9f05e59392,Predictive Toxicology Challenge,-1,-1
63876444727ddf9f05e59394,NSURL-2019 Shared Task 8: Semantic Question Similarity in Arabic,-1,-1
63876444727ddf9f05e59396,DeeperForensics-1.0,-1,-1
63876444727ddf9f05e59398,Action-Camera Parking,-1,-1
63876444727ddf9f05e5939a,Dafonts Free,-1,-1
63876444727ddf9f05e5939c,ELITR ECA,-1,-1
63876444727ddf9f05e5939e,PubMed RCT,-1,-1
63876444727ddf9f05e593a0,ClonedPerson,-1,-1
63876444727ddf9f05e593a2,EmoryNLP,-1,-1
63876444727ddf9f05e593a4,BB-MAS,-1,-1
63876444727ddf9f05e593a6,Robotic Pushing,-1,-1
63876444727ddf9f05e593a8,BarkNet 1.0,-1,-1
63876444727ddf9f05e593aa,KPTimes,-1,-1
63876444727ddf9f05e593ac,BrazilDam Dataset,-1,-1
63876444727ddf9f05e593ae,mC4,-1,-1
63876444727ddf9f05e593b0,Horse-10,-1,-1
63876444727ddf9f05e593b2,CSQA,-1,-1
63876444727ddf9f05e593b4,Neural Audio Fingerprint Dataset,-1,-1
63876444727ddf9f05e593b6,KenyanFood13,-1,-1
63876444727ddf9f05e593b8,Salinas,-1,-1
63876444727ddf9f05e593ba,MASATI,-1,-1
63876444727ddf9f05e593bc,Sepehr_RumTel01,-1,-1
63876444727ddf9f05e593be,Google,-1,-1
63876444727ddf9f05e593c0,Aachen Day-Night,-1,-1
63876444727ddf9f05e593c2,YASO,-1,-1
63876444727ddf9f05e593c4,CSI,-1,-1
63876444727ddf9f05e593c6,MuSeRC,-1,-1
63876444727ddf9f05e593c8,Zillow Indoor Dataset,-1,-1
63876444727ddf9f05e593ca,MIMI dataset,-1,-1
63876444727ddf9f05e593cc,KPI-EDGAR,-1,-1
63876444727ddf9f05e593ce,ISBNet,-1,-1
63876444727ddf9f05e593d0,Total-Text,-1,-1
63876444727ddf9f05e593d2,Mario AI,-1,-1
63876444727ddf9f05e593d4,Lyra,-1,-1
63876444727ddf9f05e593d6,ImageNet-C,-1,-1
63876444727ddf9f05e593d8,IJB-C,-1,-1
63876444727ddf9f05e593da,YT-UGC,-1,-1
63876444727ddf9f05e593dc,VitaminC,-1,-1
63876444727ddf9f05e593de,Extended Synthetic and Photogrammetric Aerial-Image Dataset,-1,-1
63876444727ddf9f05e593e0,PRONOSTIA Bearing Dataset,-1,-1
63876444727ddf9f05e593e2,MAFW,-1,-1
63876444727ddf9f05e593e4,Hands in Action,-1,-1
63876444727ddf9f05e593e6,MIMIC-SPARQL,-1,-1
63876444727ddf9f05e593e8,PDEBench,-1,-1
63876444727ddf9f05e593ea,Collaborative SLAM Dataset,-1,-1
63876444727ddf9f05e593ec,Points of correspondence,-1,-1
63876444727ddf9f05e593ee,fGn Traffic Traces,-1,-1
63876444727ddf9f05e593f0,FilmStills,-1,-1
63876444727ddf9f05e593f2,Families In Wild Multimedia,-1,-1
63876444727ddf9f05e593f4,Humans Interacting with Common Objects,-1,-1
63876444727ddf9f05e593f6,KAIST Urban,-1,-1
63876444727ddf9f05e593f8,Circuit Graph Hand Drawn 1152,-1,-1
63876444727ddf9f05e593fa,PROMISE12,-1,-1
63876444727ddf9f05e593fc,OpenViDial,-1,-1
63876444727ddf9f05e593fe,HowTo100M,-1,-1
63876444727ddf9f05e59400,ActivityNet Entities,-1,-1
63876444727ddf9f05e59402,Vietnamese Speech Data by Mobile Phone,-1,-1
63876444727ddf9f05e59404,Moving MNIST,-1,-1
63876444727ddf9f05e59406,Lenta Short Sentences,-1,-1
63876444727ddf9f05e59408,Photozilla,-1,-1
63876444727ddf9f05e5940a,"1,003 People-Driver Behavior Collection Data",-1,-1
63876444727ddf9f05e5940c,LIRIS human activities dataset,-1,-1
63876444727ddf9f05e5940e,Cross-View Cross-Scene Multi-View Crowd Counting Dataset,-1,-1
63876444727ddf9f05e59410,VFITex,-1,-1
63876444727ddf9f05e59412,EMBER,-1,-1
63876444727ddf9f05e59414,NewsCLIPpings,-1,-1
63876444727ddf9f05e59416,20Newsgroup (10 tasks),-1,-1
63876444727ddf9f05e59418,ErhuPT,-1,-1
63876444727ddf9f05e5941a,Mixed Speech with Chinese and English Data by Mobile Phone,-1,-1
63876444727ddf9f05e5941c,MAritime SATellite Imagery dataset,-1,-1
63876444727ddf9f05e5941e,Artie Bias Corpus,-1,-1
63876444727ddf9f05e59420,ChaLearn Pose,-1,-1
63876444727ddf9f05e59422,CASIA V2,-1,-1
63876444727ddf9f05e59424,PlantVillage,-1,-1
63876444727ddf9f05e59426,AraCovid19-SSD,-1,-1
63876444727ddf9f05e59428,"18,880 Images of 466 People - 3D Instance Segmentation and 22 Landmarks Annotation Data of Human Body",-1,-1
63876444727ddf9f05e5942a,FineGym,-1,-1
63876444727ddf9f05e5942c,MAEC,-1,-1
63876444727ddf9f05e5942e,RobustPointSet,-1,-1
63876444727ddf9f05e59430,SentiMix,-1,-1
63876444727ddf9f05e59432,32vis,-1,-1
63876444727ddf9f05e59434,NucMM,-1,-1
63876444727ddf9f05e59436,A Dataset of Journalists' Interactions with Their Readership,-1,-1
63876444727ddf9f05e59438,UAGD,-1,-1
63876444727ddf9f05e5943a,Open Annotations of Single Image Surfaces,-1,-1
63876444727ddf9f05e5943c,COUGH,-1,-1
63876444727ddf9f05e5943e,RaindropsOnWindshield,-1,-1
63876444727ddf9f05e59440,BP4D,-1,-1
63876444727ddf9f05e59442,A Synthetic Immersive Large-Volume Plenoptic Dataset,-1,-1
63876444727ddf9f05e59444,Wisesight Sentiment Corpus,-1,-1
63876444727ddf9f05e59446,HoVer,-1,-1
63876444727ddf9f05e59448,ClaimBuster,-1,-1
63876444727ddf9f05e5944a,TIMo,-1,-1
63876444727ddf9f05e5944c,Human3.6M,-1,-1
63876444727ddf9f05e5944e,LAnguage Model Analysis,-1,-1
63876444727ddf9f05e59450,WinoGrande,-1,-1
63876444727ddf9f05e59452,Adversarial NLI,-1,-1
63876444727ddf9f05e59454,FDDB-360,-1,-1
63876444727ddf9f05e59456,Immediacy Dataset,-1,-1
63876444727ddf9f05e59458,AMALGUM,-1,-1
63876444727ddf9f05e5945a,STREETSCORE--PREDICTING THE PERCEIVED SAFETY OF ONE MILLION STREETSCAPES,-1,-1
63876444727ddf9f05e5945c,DeSMOG,-1,-1
63876444727ddf9f05e5945e,INRIA Aerial Image Labeling,-1,-1
63876444727ddf9f05e59460,GitTables,-1,-1
63876444727ddf9f05e59462,VLN-CE,-1,-1
63876444727ddf9f05e59464,Chinese Machine Reading Comprehension 2017,-1,-1
63876444727ddf9f05e59466,High-Resolution Web Stereo Image,-1,-1
63876444727ddf9f05e59468,"NVGaze: An Anatomically-Informed Dataset for Low-Latency, Near-Eye Gaze Estimation",-1,-1
63876444727ddf9f05e5946a,Mathematics Dataset,-1,-1
63876444727ddf9f05e5946c,Simulacra Aesthetic Captions,-1,-1
63876444727ddf9f05e5946e,MultiSense,-1,-1
63876444727ddf9f05e59470,STEW,-1,-1
63876444727ddf9f05e59472,LARa,-1,-1
63876444727ddf9f05e59474,deepMTJ_IEEEtbme,-1,-1
63876444727ddf9f05e59476,ObjectNet,-1,-1
63876444727ddf9f05e59478,203 People - Taiwanese Mandarin Speech Data by Mobile Phone_Guiding,-1,-1
63876444727ddf9f05e5947a,Off_Near_sequential,-1,-1
63876444727ddf9f05e5947c,Self-Taught Learning 10,-1,-1
63876444727ddf9f05e5947e,Textual Entailment Recognition for Russian,-1,-1
63876444727ddf9f05e59480,OnFocus Detection In the Wild,-1,-1
63876444727ddf9f05e59482,ISI_Bengali_Character,-1,-1
63876444727ddf9f05e59484,CoDraw,-1,-1
63876444727ddf9f05e59486,ARDIS,-1,-1
63876444727ddf9f05e59488,OpenLORIS-object,-1,-1
63876444727ddf9f05e5948a,Arabic Speech Corpus,-1,-1
63876444727ddf9f05e5948c,ICDAR 2017,-1,-1
63876444727ddf9f05e5948e,Tour20,-1,-1
63876444727ddf9f05e59490,DramaQA,-1,-1
63876444727ddf9f05e59492,FSOD,-1,-1
63876444727ddf9f05e59494,TREK-150,-1,-1
63876444727ddf9f05e59496,Southern California Seismic Network Data,-1,-1
63876444727ddf9f05e59498,Vi-Fi Multi-modal Dataset,-1,-1
63876444727ddf9f05e5949a,MS^2,-1,-1
63876444727ddf9f05e5949c,BigHand2.2M Benchmark,-1,-1
63876444727ddf9f05e5949e,DGTA-SeaDronesSee,-1,-1
63876444727ddf9f05e594a0,DeepTrash,-1,-1
63876444727ddf9f05e594a2,20000 utterances,-1,-1
63876444727ddf9f05e594a4,MuMu,-1,-1
63876444727ddf9f05e594a6,LGI-PPGI-Face-Video-Database,-1,-1
63876444727ddf9f05e594a8,OTB-2015,-1,-1
63876444727ddf9f05e594aa,AmsterTime: A Visual Place Recognition Benchmark Dataset for Severe Domain Shift,-1,-1
63876444727ddf9f05e594ac,3D-BSLS-6D,-1,-1
63876444727ddf9f05e594ae,Crello dataset,-1,-1
63876444727ddf9f05e594b0,WikiMulti: a Corpus for Cross-Lingual Summarization,-1,-1
63876444727ddf9f05e594b2,DeCOCO,-1,-1
63876444727ddf9f05e594b4,Geometry3K,-1,-1
63876444727ddf9f05e594b6,Chinese Simile,-1,-1
63876444727ddf9f05e594b8,PDNC,-1,-1
63876444727ddf9f05e594ba,EGTEA Gaze+,-1,-1
63876444727ddf9f05e594bc,australian,-1,-1
63876444727ddf9f05e594be,Las Cumbres Observatory Cosmic Ray Dataset,-1,-1
63876444727ddf9f05e594c0,FewGLUE_64_labeled,-1,-1
63876444727ddf9f05e594c2,HurricaneEmo,-1,-1
63876444727ddf9f05e594c4,FB122,-1,-1
63876444727ddf9f05e594c6,Energy Consumption Curves of 499 Customers from Spain,-1,-1
63876444727ddf9f05e594c8,IGC,-1,-1
63876444727ddf9f05e594ca,Functional Map of the World,-1,-1
63876444727ddf9f05e594cc,The RBO Dataset of Articulated Objects and Interactions,-1,-1
63876444727ddf9f05e594ce,PheMT,-1,-1
63876444727ddf9f05e594d0,RFW,-1,-1
63876444727ddf9f05e594d2,PubMed Tables One Million,-1,-1
63876444727ddf9f05e594d4,MannequinChallenge,-1,-1
63876444727ddf9f05e594d6,Individual household electric power consumption Data Set,-1,-1
63876444727ddf9f05e594d8,3DPeople Dataset,-1,-1
63876444727ddf9f05e594da,House3D Environment,-1,-1
63876444727ddf9f05e594dc,CoAuthor,-1,-1
63876444727ddf9f05e594de,LIVE Livestream,-1,-1
63876444727ddf9f05e594e0,Vietnamese Multiple-choice Machine Reading Comprehension Corpus,-1,-1
63876444727ddf9f05e594e2,CERBERUS DARPA Subterranean Challenge Datasets,-1,-1
63876444727ddf9f05e594e4,ADE-Affordance,-1,-1
63876444727ddf9f05e594e6,WHAMR!,-1,-1
63876444727ddf9f05e594e8,Human Video Instance Segmentation Dataset,-1,-1
63876444727ddf9f05e594ea,AU Dataset for Visuo-Haptic Object Recognition for Robots,-1,-1
63876444727ddf9f05e594ec,Human Gait Dataset,-1,-1
63876444727ddf9f05e594ee,Manually Annotated Sub-Corpus,-1,-1
63876444727ddf9f05e594f0,Wiki-ZSL,-1,-1
63876444727ddf9f05e594f2,CUB-200-2011,-1,-1
63876444727ddf9f05e594f4,RWanda Built-up Region Segmentation,-1,-1
63876444727ddf9f05e594f6,Basic Dataset for Sorani Kurdish Automatic Speech Recognition,-1,-1
63876444727ddf9f05e594f8,MAMS,-1,-1
63876444727ddf9f05e594fa,Semi-iNat,-1,-1
63876444727ddf9f05e594fc,Head-Pose Detection,-1,-1
63876444727ddf9f05e594fe,ArCOV-19,-1,-1
63876444727ddf9f05e59500,CSTR VCTK Corpus,-1,-1
63876444727ddf9f05e59502,Fluo-C3DH-A549-SIM,-1,-1
63876444727ddf9f05e59504,SEMCAT,-1,-1
63876444727ddf9f05e59506,Person In Context 2021,-1,-1
63876444727ddf9f05e59508,CxC,-1,-1
63876444727ddf9f05e5950a,OULU-NPU,-1,-1
63876444727ddf9f05e5950c,Early Breast Cancer Core-Needle Biopsy WSI,-1,-1
63876444727ddf9f05e5950e,TIAGE,-1,-1
63876444727ddf9f05e59510,Potsdam Commentary Corpus,-1,-1
63876444727ddf9f05e59512,VITON,-1,-1
63876444727ddf9f05e59514,DQN Replay Dataset,-1,-1
63876444727ddf9f05e59516,3D Living_Face & Anti_Spoofing Data,-1,-1
63876444727ddf9f05e59518,ToxCast(scaffold),-1,-1
63876444727ddf9f05e5951a,COMPARE,-1,-1
63876444727ddf9f05e5951c,Honda Scenes Dataset,-1,-1
63876444727ddf9f05e5951e,AppleScabFDs,-1,-1
63876444727ddf9f05e59520,Pesteh-Set,-1,-1
63876444727ddf9f05e59522,Minimalist Histopathology image analysis dataset,-1,-1
63876444727ddf9f05e59524,Tencent ML-Images,-1,-1
63876444727ddf9f05e59526,DuReader,-1,-1
63876444727ddf9f05e59528,KIT Motion-Language,-1,-1
63876444727ddf9f05e5952a,101 Hours – Scene Noise Data by Voice Recorder,-1,-1
63876444727ddf9f05e5952c,Top Comment or Flop Comment?,-1,-1
63876444727ddf9f05e5952e,YCB-Slide: A tactile interaction dataset,-1,-1
63876444727ddf9f05e59530,Emotion in Music Database,-1,-1
63876444727ddf9f05e59532,UnrealEgo,-1,-1
63876444727ddf9f05e59534,Samanantar,-1,-1
63876444727ddf9f05e59536,Chinese Children Speech Data,-1,-1
63876444727ddf9f05e59538,Handwriting OCR Data of Japanese and Korean,-1,-1
63876444727ddf9f05e5953a,ShanghaiTech MARS Dynamic OLAT Dataset,-1,-1
63876444727ddf9f05e5953c,Object Discovery,-1,-1
63876444727ddf9f05e5953e,"1,025 Hours - Mandarin Strong Accent Speech Data by Mobile Phone",-1,-1
63876444727ddf9f05e59540,MSK,-1,-1
63876444727ddf9f05e59542,ATD-12K,-1,-1
63876444727ddf9f05e59544,French Dialect Samples,-1,-1
63876444727ddf9f05e59546,Wendi,-1,-1
63876444727ddf9f05e59548,ICSI Meeting Recorder Dialog Act Corpus,-1,-1
63876444727ddf9f05e5954a,Twitch-FIFA,-1,-1
63876444727ddf9f05e5954c,Office-Caltech-10,-1,-1
63876444727ddf9f05e5954e,Wikipedia Squirrel,-1,-1
63876444727ddf9f05e59550,Berkeley MHAD,-1,-1
63876444727ddf9f05e59552,BACC-18,-1,-1
63876444727ddf9f05e59554,Korean Speech Data by Mobile Phone_Reading,-1,-1
63876444727ddf9f05e59556,MIT-BIH Atrial Fibrilation Database,-1,-1
63876444727ddf9f05e59558,Market1501-Attributes,-1,-1
63876444727ddf9f05e5955a,FaceForensics,-1,-1
63876444727ddf9f05e5955c,QuaRTz Dataset,-1,-1
63876444727ddf9f05e5955e,Dialog System Technology Challenges Task 1,-1,-1
63876444727ddf9f05e59560,COQE,-1,-1
63876444727ddf9f05e59562,AudioSet,-1,-1
63876444727ddf9f05e59564,WikiCaps,-1,-1
63876444727ddf9f05e59566,Kompetencer,-1,-1
63876444727ddf9f05e59568,ASSET Corpus,-1,-1
63876444727ddf9f05e5956a,AFLW-19,-1,-1
63876444727ddf9f05e5956c,So2Sat LCZ42,-1,-1
63876444727ddf9f05e5956e,DLBCL-Morph,-1,-1
63876444727ddf9f05e59570,Synthetic Object Preference Adaptation Data,-1,-1
63876444727ddf9f05e59572,CzEng 2.0 Parallel Corpus,-1,-1
63876444727ddf9f05e59574,Multi-Attribute Labelled Faces,-1,-1
63876444727ddf9f05e59576,Message Content Rephrasing,-1,-1
63876444727ddf9f05e59578,German Lips,-1,-1
63876444727ddf9f05e5957a,CrowdPose,-1,-1
63876444727ddf9f05e5957c,MedQuAD,-1,-1
63876444727ddf9f05e5957e,EvoGym,-1,-1
63876444727ddf9f05e59580,NR-HCPI,-1,-1
63876444727ddf9f05e59582,PNPB dataset,-1,-1
63876444727ddf9f05e59584,Open Graph Benchmark,-1,-1
63876444727ddf9f05e59586,WikiQA,-1,-1
63876444727ddf9f05e59588,Mila Simulated Floods,-1,-1
63876444727ddf9f05e5958a,PTL,-1,-1
63876444727ddf9f05e5958c,Bimanual Actions Dataset,-1,-1
63876444727ddf9f05e5958e,NMED-H,-1,-1
63876444727ddf9f05e59590,Youtubean,-1,-1
63876444727ddf9f05e59592,Bangladeshi Sign Language Image Dataset,-1,-1
63876444727ddf9f05e59594,CholecT45,-1,-1
63876444727ddf9f05e59596,DBP-5L (Japanese),-1,-1
63876444727ddf9f05e59598,PointPattern,-1,-1
63876444727ddf9f05e5959a,Products-10K,-1,-1
63876444727ddf9f05e5959c,RuMedBench,-1,-1
63876444727ddf9f05e5959e,Mars DTM Estimation,-1,-1
63876444727ddf9f05e595a0,LFPW,-1,-1
63876444727ddf9f05e595a2,OpenSubtitles,-1,-1
63876444727ddf9f05e595a4,BdSLImset,-1,-1
63876444727ddf9f05e595a6,CMU Document Grounded Conversations Dataset,-1,-1
63876444727ddf9f05e595a8,MultiviewC,-1,-1
63876444727ddf9f05e595aa,MARS,-1,-1
63876444727ddf9f05e595ac,HouseExpo,-1,-1
63876444727ddf9f05e595ae,WPC,-1,-1
63876444727ddf9f05e595b0,TimeDial,-1,-1
63876444727ddf9f05e595b2,The Roundabout Drone Dataset - Naturalistic Trajectories of Vehicles and Vulnerable Road Users Recorded at German Roundabouts,-1,-1
63876444727ddf9f05e595b4,CurveLanes,-1,-1
63876444727ddf9f05e595b6,Digit-Five,-1,-1
63876444727ddf9f05e595b8,GYAFC,-1,-1
63876444727ddf9f05e595ba,PMData,-1,-1
63876444727ddf9f05e595bc,GQN rooms-ring-camera,-1,-1
63876444727ddf9f05e595be,Alexa Point of View,-1,-1
63876444727ddf9f05e595c0,BirdVox-DCASE-20k,-1,-1
63876444727ddf9f05e595c2,Novel COVID-19 Chestxray Repository,-1,-1
63876444727ddf9f05e595c4,QUASAR,-1,-1
63876444727ddf9f05e595c6,CloudCast: A Satellite-Based Dataset and Baseline for Forecasting Clouds,-1,-1
63876444727ddf9f05e595c8,MIMIC-IV,-1,-1
63876444727ddf9f05e595ca,NSynth,-1,-1
63876444727ddf9f05e595cc,PAXRay: A Projected dataset for the segmentation of Anatomical structures in X-Ray data,-1,-1
63876444727ddf9f05e595ce,LAV-DF,-1,-1
63876444727ddf9f05e595d0,ePillID,-1,-1
63876444727ddf9f05e595d2,Cross-Domain UAV Data Sets with Increased Number of Sensors for developing Advanced and Novel Estimators,-1,-1
63876444727ddf9f05e595d4,MSRDailyActivity3D,-1,-1
63876444727ddf9f05e595d6,Out the Window,-1,-1
63876444727ddf9f05e595d8,Navigation Turing Test,-1,-1
63876444727ddf9f05e595da,ImageNet-X,-1,-1
63876444727ddf9f05e595dc,GDA,-1,-1
63876444727ddf9f05e595de,EUEN17037_Daylight_and_View_Standard_TestDataSet,-1,-1
63876444727ddf9f05e595e0,UFO Cherry Tree Point Clouds,-1,-1
63876444727ddf9f05e595e2,"4,082 Families-Family Face Data",-1,-1
63876444727ddf9f05e595e4,SSP-3D,-1,-1
63876444727ddf9f05e595e6,BAFMD,-1,-1
63876444727ddf9f05e595e8,A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work,-1,-1
63876444727ddf9f05e595ea,ContraCAT,-1,-1
63876444727ddf9f05e595ec,ProsocialDialog,-1,-1
63876444727ddf9f05e595ee,ESR1_ant target of LIT-PCBA Dataset,-1,-1
63876444727ddf9f05e595f0,Physically Unconstrained Gaze Estimation in the Wild,-1,-1
63876444727ddf9f05e595f2,DistNLI,-1,-1
63876444727ddf9f05e595f4,BAR,-1,-1
63876444727ddf9f05e595f6,Peripapillary OCT Images,-1,-1
63876444727ddf9f05e595f8,MedMNIST v2,-1,-1
63876444727ddf9f05e595fa,VMRD,-1,-1
63876444727ddf9f05e595fc,UofTPed50,-1,-1
63876444727ddf9f05e595fe,Large-scale Attribute Dataset,-1,-1
63876444727ddf9f05e59600,Oracle-MNIST,-1,-1
63876444727ddf9f05e59602,SELTO Dataset,-1,-1
63876444727ddf9f05e59604,Multilingual Corpus from United Nation Documents,-1,-1
63876444727ddf9f05e59606,TriviaQA,-1,-1
63876444727ddf9f05e59608,TRACT,-1,-1
63876444727ddf9f05e5960a,Solar-Power,-1,-1
63876444727ddf9f05e5960c,Data Loss repository,-1,-1
63876444727ddf9f05e5960e,BCN_20000,-1,-1
63876444727ddf9f05e59610,Corn Seeds Dataset,-1,-1
63876444727ddf9f05e59612,Stanford 3D Scanning Repository,-1,-1
63876444727ddf9f05e59614,Egocentric Dataset,-1,-1
63876444727ddf9f05e59616,DND,-1,-1
63876444727ddf9f05e59618,102 Category Flower Dataset,-1,-1
63876444727ddf9f05e5961a,Genocide Transcript Corpus (GTC): Topic-Based Paragraph Classification in Genocide-Related Court Transcripts,-1,-1
63876444727ddf9f05e5961c,emrQA,-1,-1
63876444727ddf9f05e5961e,Lila,-1,-1
63876444727ddf9f05e59620,ETH BIWI Walking Pedestrians,-1,-1
63876444727ddf9f05e59622,Multi-View Operating Room,-1,-1
63876444727ddf9f05e59624,Konzil,-1,-1
63876444727ddf9f05e59626,The results of the Magma benchmark,-1,-1
63876444727ddf9f05e59628,COCO-Tasks,-1,-1
63876444727ddf9f05e5962a,MagicData-RAMC,-1,-1
63876444727ddf9f05e5962c,MultiNLI,-1,-1
63876444727ddf9f05e5962e,Realworld Annotated Few-shot Tasks,-1,-1
63876444727ddf9f05e59630,BioLeaflets,-1,-1
63876444727ddf9f05e59632,Open4Business,-1,-1
63876444727ddf9f05e59634,BuildingNet,-1,-1
63876444727ddf9f05e59636,LEAF-QA,-1,-1
63876444727ddf9f05e59638,IDRiD,-1,-1
63876445727ddf9f05e5963a,VOT2013,-1,-1
63876445727ddf9f05e5963c,Wireless-Intelligence,-1,-1
63876445727ddf9f05e5963e,BAM!,-1,-1
63876445727ddf9f05e59640,Image and Video Advertisements,-1,-1
63876445727ddf9f05e59642,SaL-Lightning,-1,-1
63876445727ddf9f05e59644,VGG-Sound Sync,-1,-1
63876445727ddf9f05e59646,You Snooze You Win - The PhysioNet Computing in Cardiology Challenge 2018,-1,-1
63876445727ddf9f05e59648,CDC fluview,-1,-1
63876445727ddf9f05e5964a,OpenLane,-1,-1
63876445727ddf9f05e5964c,arXMLiv:08.2018,-1,-1
63876445727ddf9f05e5964e,CheXpert,-1,-1
63876445727ddf9f05e59650,Stanford Emotional Narratives Dataset,-1,-1
63876445727ddf9f05e59652,arXiv-200,-1,-1
63876445727ddf9f05e59654,GDXray+,-1,-1
63876445727ddf9f05e59656,DPC-Captions,-1,-1
63876445727ddf9f05e59658,The Boston Housing Dataset,-1,-1
63876445727ddf9f05e5965a,CUHK-QA,-1,-1
63876445727ddf9f05e5965c,JSUT Corpus,-1,-1
63876445727ddf9f05e5965e,UrbanLoco,-1,-1
63876445727ddf9f05e59660,Sleep-EDF,-1,-1
63876445727ddf9f05e59662,Cube++,-1,-1
63876445727ddf9f05e59664,CMU DoG,-1,-1
63876445727ddf9f05e59666,PhysioNet Challenge 2020,-1,-1
63876445727ddf9f05e59668,concatenated-bAbI,-1,-1
63876445727ddf9f05e5966a,FSDD,-1,-1
63876445727ddf9f05e5966c,ConvQuestions,-1,-1
63876445727ddf9f05e5966e,PDDLGym Taskography,-1,-1
63876445727ddf9f05e59670,MIT-BIH AFDB,-1,-1
63876445727ddf9f05e59672,Emotion aware Dialogue Act,-1,-1
63876445727ddf9f05e59674,Data Visualizations via Question Answering,-1,-1
63876445727ddf9f05e59676,ODSQA,-1,-1
63876445727ddf9f05e59678,NASA Perseverance,-1,-1
63876445727ddf9f05e5967a,Ballroom,-1,-1
63876445727ddf9f05e5967c,PointCloud-C,-1,-1
63876445727ddf9f05e5967e,Retrieval Question-Answering,-1,-1
63876445727ddf9f05e59680,CLEVR-Hans,-1,-1
63876445727ddf9f05e59682,TJU-DHD,-1,-1
63876445727ddf9f05e59684,Sturm,-1,-1
63876445727ddf9f05e59686,zaid allal,-1,-1
63876445727ddf9f05e59688,BC2GM,-1,-1
63876445727ddf9f05e5968a,Reflective essays on CS TA experience,-1,-1
63876445727ddf9f05e5968c,Passenger Behavior Recognition Data,-1,-1
63876445727ddf9f05e5968e,Unified Photometric Image Quality,-1,-1
63876445727ddf9f05e59690,Dataset of Annotated Car Trajectories,-1,-1
63876445727ddf9f05e59692,UDD,-1,-1
63876445727ddf9f05e59694,NILoc,-1,-1
63876445727ddf9f05e59696,eAppleScab,-1,-1
63876445727ddf9f05e59698,RED,-1,-1
63876445727ddf9f05e5969a,Simulated particle-level dataset of ttbar with PU200 using Pythia8+Delphes3 for machine learned particle flow (MLPF),-1,-1
63876445727ddf9f05e5969c,Lazaro Corpus,-1,-1
63876445727ddf9f05e5969e,moon phases and derived,-1,-1
63876445727ddf9f05e596a0,Image Matching Challenge Phototourism,-1,-1
63876445727ddf9f05e596a2,WebLI,-1,-1
63876445727ddf9f05e596a4,TinyVIRAT,-1,-1
63876445727ddf9f05e596a6,COCO Earthquake,-1,-1
63876445727ddf9f05e596a8,Mid-Air Dataset,-1,-1
63876445727ddf9f05e596aa,AG's corpus of news articlesNews,-1,-1
63876445727ddf9f05e596ac,EtymDB 2.0,-1,-1
63876445727ddf9f05e596ae,ETH Structure-from-Motion,-1,-1
63876445727ddf9f05e596b0,Manually annotated 3-digit occupation codes from the Norwegian 1950 census,-1,-1
63876445727ddf9f05e596b2,"Wasserstein Distances, Geodesics and Barycenters of Merge Trees",-1,-1
63876445727ddf9f05e596b4,RESPIRATORY AND DRUG ACTUATION DATASET,-1,-1
63876445727ddf9f05e596b6,NCI1,-1,-1
63876445727ddf9f05e596b8,ChMusic,-1,-1
63876445727ddf9f05e596ba,YouTube-GDD,-1,-1
63876445727ddf9f05e596bc,NYC3DCars,-1,-1
63876445727ddf9f05e596be,IWSLT 2019,-1,-1
63876445727ddf9f05e596c0,Laval Indoor HDR Dataset,-1,-1
63876445727ddf9f05e596c2,ISIC 2017 Task 2,-1,-1
63876445727ddf9f05e596c4,Fingerprint Dataset,-1,-1
63876445727ddf9f05e596c6,Multilingual Audio-Visual Smartphone dataset,-1,-1
63876445727ddf9f05e596c8,CFC,-1,-1
63876445727ddf9f05e596ca,hls4ml LHC Jet dataset,-1,-1
63876445727ddf9f05e596cc,PETA,-1,-1
63876445727ddf9f05e596ce,The RobotriX,-1,-1
63876445727ddf9f05e596d0,Middlebury,-1,-1
63876445727ddf9f05e596d2,UKP Argument Annotated Essays,-1,-1
63876445727ddf9f05e596d4,HelixNet,-1,-1
63876445727ddf9f05e596d6,IACC.3,-1,-1
63876445727ddf9f05e596d8,PCQM4Mv2-LSC,-1,-1
63876445727ddf9f05e596da,CBSD68,-1,-1
63876445727ddf9f05e596dc,QReCC,-1,-1
63876445727ddf9f05e596de,CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings,-1,-1
63876445727ddf9f05e596e0,SMAC+_Def_Armored_parallel_20,-1,-1
63876445727ddf9f05e596e2,SlowFlow,-1,-1
63876445727ddf9f05e596e4,CMU Wilderness Multilingual Speech Dataset,-1,-1
63876445727ddf9f05e596e6,DSBI,-1,-1
63876445727ddf9f05e596e8,IBM-Rank-30k,-1,-1
63876445727ddf9f05e596ea,Contextualized Commonsense Inference in Dialogues,-1,-1
63876445727ddf9f05e596ec,SUN-SEG-Hard (Unseen),-1,-1
63876445727ddf9f05e596ee,PMPC,-1,-1
63876445727ddf9f05e596f0,Conceptual 12M,-1,-1
63876445727ddf9f05e596f2,BEHAVE,-1,-1
63876445727ddf9f05e596f4,YouTube-100M,-1,-1
63876445727ddf9f05e596f6,Synthetic COVID-19 CXR Dataset,-1,-1
63876445727ddf9f05e596f8,MUTAG,-1,-1
63876445727ddf9f05e596fa,HICO,-1,-1
63876445727ddf9f05e596fc,Top-View Person Re-Identification Dataset,-1,-1
63876445727ddf9f05e596fe,SURREALvols,-1,-1
63876445727ddf9f05e59700,Multi-person Human-object Interaction Dataset 72,-1,-1
63876445727ddf9f05e59702,CPSC2020,-1,-1
63876445727ddf9f05e59704,Music21,-1,-1
63876445727ddf9f05e59706,Government Privacy Instructions Corpus,-1,-1
63876445727ddf9f05e59708,Curated AFD,-1,-1
63876445727ddf9f05e5970a,PASCAL-S,-1,-1
63876445727ddf9f05e5970c,phtnsantader@gmail.com,-1,-1
63876445727ddf9f05e5970e,Penn Machine Learning Benchmarks,-1,-1
63876445727ddf9f05e59710,KINNEWS and KIRNEWS,-1,-1
63876445727ddf9f05e59712,Multi-Domain Sentiment Dataset v2.0,-1,-1
63876445727ddf9f05e59714,Elsevier OA CC-BY,-1,-1
63876445727ddf9f05e59716,Microsoft Research Paraphrase Corpus,-1,-1
63876445727ddf9f05e59718,Original Chinese Natural Language Inference,-1,-1
63876445727ddf9f05e5971a,DNA mutations,-1,-1
63876445727ddf9f05e5971c,Cryptics,-1,-1
63876445727ddf9f05e5971e,BanFakeNews,-1,-1
63876445727ddf9f05e59720,MSU Deinterlacer Benchmark,-1,-1
63876445727ddf9f05e59722,AMT Objects,-1,-1
63876445727ddf9f05e59724,OTT-QA,-1,-1
63876445727ddf9f05e59726,Xamarin Q&A,-1,-1
63876445727ddf9f05e59728,SKINL2,-1,-1
63876445727ddf9f05e5972a,Japanese Adversarial Natural Language Inference,-1,-1
63876445727ddf9f05e5972c,LDC2017T10,-1,-1
63876445727ddf9f05e5972e,RWCP-SSD-Onomatopoeia,-1,-1
63876445727ddf9f05e59730,Groove MIDI Dataset,-1,-1
63876445727ddf9f05e59732,Generic Object ZSL Dataset,-1,-1
63876445727ddf9f05e59734,FFHQ,-1,-1
63876445727ddf9f05e59736,MusicBrainz20K,-1,-1
63876445727ddf9f05e59738,CIFAR100-LT,-1,-1
63876445727ddf9f05e5973a,MSVD,-1,-1
63876445727ddf9f05e5973c,PCDS,-1,-1
63876445727ddf9f05e5973e,JetNet,-1,-1
63876445727ddf9f05e59740,3DIdent,-1,-1
63876445727ddf9f05e59742,CHiME Speech Separation and Recognition Challenge,-1,-1
63876445727ddf9f05e59744,DIP-IMU,-1,-1
63876445727ddf9f05e59746,TAU Urban Acoustic Scenes 2019 Mobile,-1,-1
63876445727ddf9f05e59748,MFH,-1,-1
63876445727ddf9f05e5974a,BIOMRC,-1,-1
63876445727ddf9f05e5974c,Mobility Scenario FIMU,-1,-1
63876445727ddf9f05e5974e,UCF-Crime,-1,-1
63876445727ddf9f05e59750,Automated Programming Progress Standard,-1,-1
63876445727ddf9f05e59752,Fluo-N2DH-GOWT1,-1,-1
63876445727ddf9f05e59754,SVBRDF Database Bonn,-1,-1
63876445727ddf9f05e59756,INSTRE,-1,-1
63876445727ddf9f05e59758,UCSF PDGM,-1,-1
63876445727ddf9f05e5975a,Long Video Dataset (3X),-1,-1
63876445727ddf9f05e5975c,Ankara University Turkish Sign Language Dataset,-1,-1
63876445727ddf9f05e5975e,Chaoyang,-1,-1
63876445727ddf9f05e59760,DocBank-Table,-1,-1
63876445727ddf9f05e59762,TAO,-1,-1
63876445727ddf9f05e59764,seeds,-1,-1
63876445727ddf9f05e59766,Foreigner Speaking Chinese Speech Data,-1,-1
63876445727ddf9f05e59768,Bottles and Cups Dataset | Household Objects,-1,-1
63876445727ddf9f05e5976a,RESISC45,-1,-1
