{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Openslide\n\n### As a new user of openslide I wanted to explore this library and apply it to the PANDA dataset.\n\n### I was searching in the public notebooks but couldn't find any dedicated to openslide.\n\n## So here it is!\n\n### In this notebook you will learn how to extract embedded information and metadata from our Generic tiled TIFF PANDA dataset using OpenSlide and DeepZoom Classes.\n\n### Here is the link for the API https://openslide.org/api/python/\n\n## Enjoy!"},{"metadata":{},"cell_type":"markdown","source":"# Abstract\n\nOpenSlide Python is a Python interface to the OpenSlide library.\n\nOpenSlide is a C library that provides a simple interface for reading whole-slide images, also known as virtual slides, which are high-resolution images used in digital pathology. These images can occupy tens of gigabytes when uncompressed, and so cannot be easily read using standard tools or libraries, which are designed for images that can be comfortably uncompressed into RAM. Whole-slide images are typically multi-resolution; OpenSlide allows reading a small amount of image data at the resolution closest to a desired zoom level."},{"metadata":{},"cell_type":"markdown","source":"# Imports and Loading"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\n\nimport numpy as np\nimport openslide\nfrom openslide import deepzoom\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Images / Masks Directories\nimages_dir = \"../input/prostate-cancer-grade-assessment/train_images/\"\nmasks_dir = \"../input/prostate-cancer-grade-assessment/train_label_masks/\"\n\n#Files\nimage_files = os.listdir(images_dir)\nmask_files = os.listdir(masks_dir)\nmask_files_cleaned = [i.replace(\"_mask\", \"\") for i in mask_files]\n\n#Clean Images without Masks\nimages_with_masks = list(set(image_files).intersection(mask_files_cleaned))\nlen(image_files), len(mask_files), len(images_with_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_file = '00928370e2dfeb8a507667ef1d4efcbb.tiff'\nmask_file = '00928370e2dfeb8a507667ef1d4efcbb_mask.tiff'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OpenSlide object\n\nAn open whole-slide image."},{"metadata":{"trusted":true},"cell_type":"code","source":"image = openslide.OpenSlide(os.path.join(images_dir, image_file))\nmask = openslide.OpenSlide(os.path.join(masks_dir, mask_file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(image))\ntype(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_level_count = image.level_count\nmask_level_count = mask.level_count\nprint(img_level_count, mask_level_count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 3 levels of magnification"},{"metadata":{"trusted":true},"cell_type":"code","source":"detect_format = openslide.PROPERTY_NAME_VENDOR\nprint(detect_format)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size1 = image.level_dimensions[0]\nimage_size2 = image.level_dimensions[1]\nimage_size3 = image.level_dimensions[2]\nprint(image_size1, image_size2, image_size3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is an example of 3 level dimensions in the same image"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_size1 = mask.level_dimensions[0]\nmask_size2 = mask.level_dimensions[1]\nmask_size3 = mask.level_dimensions[2]\nprint(mask_size1, mask_size2, mask_size3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same dimensions for the 3 levels of masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_dwn1 = image.level_downsamples[0]\nimage_dwn2 = image.level_downsamples[1]\nimage_dwn3 = image.level_downsamples[2]\nprint(image_dwn1, image_dwn2, image_dwn3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A list of downsample factors 1, 4 and 16 for each level of the slide"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_dwn1 = mask.level_downsamples[0]\nmask_dwn2 = mask.level_downsamples[1]\nmask_dwn3 = mask.level_downsamples[2]\nprint(mask_dwn1, mask_dwn2, mask_dwn3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still the same for the masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"image.properties","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask.properties","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.associated_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask.associated_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.read_region((0, 0), 2 , (512, 512))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read a specfic region of the WSI based on location, level and size of region"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask.read_region((0, 0), 2 , (512, 512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.get_best_level_for_downsample(18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.get_thumbnail((300,300))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DeepZoomGenerator\n\nOpenSlide Python provides functionality for generating individual Deep Zoom tiles from slide objects. This is useful for displaying whole-slide images in a web browser without converting the entire slide to Deep Zoom or a similar format.\n\nNot useful in this competition but good to know for further applications."},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom = openslide.deepzoom.DeepZoomGenerator(image, tile_size=254, overlap=1, limit_bounds=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(zoom))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.level_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.tile_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.level_tiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.level_dimensions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.get_dzi('png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"format(zoom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.get_tile(13, (2, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.get_tile_coordinates(13, (2, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zoom.get_tile_dimensions(13, (2, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}